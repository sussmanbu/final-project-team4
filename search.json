[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This comes from the file data.qmd.\nYour first steps in this project will be to find data to work on.\nI recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.\nInitially, you will study one dataset but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable. Data from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components."
  },
  {
    "objectID": "data.html#what-makes-a-good-data-set",
    "href": "data.html#what-makes-a-good-data-set",
    "title": "Data",
    "section": "What makes a good data set?",
    "text": "What makes a good data set?\n\nData you are interested in and care about.\nData where there are a lot of potential questions that you can explore.\nA data set that isn’t completely cleaned already.\nMultiple sources for data that you can combine.\nSome type of time and/or location component."
  },
  {
    "objectID": "data.html#where-to-keep-data",
    "href": "data.html#where-to-keep-data",
    "title": "Data",
    "section": "Where to keep data?",
    "text": "Where to keep data?\nBelow 50mb: In dataset folder\nAbove 50mb: In dataset_ignore folder. This folder will be ignored by git so you’ll have to manually sync these files across your team.\n\nSharing your data\nFor small datasets (&lt;50mb), you can use the dataset folder that is tracked by github. Add the files just like you would any other file.\nIf you create a folder named data this will cause problems.\nFor larger datasets, you’ll need to create a new folder in the project root directory named dataset-ignore. This will be ignored by git (based off the .gitignore file in the project root directory) which will help you avoid issues with Github’s size limits. Your team will have to manually make sure the data files in dataset-ignore are synced across team members.\nYour load_and_clean_data.R file is how you will load and clean your data. Here is a an example of a very simple one.\n\nsource(\n  \"scripts/load_and_clean_data.R\",\n  echo = FALSE # Use echo=FALSE or omit it to avoid code output  \n)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tune         1.1.2\n✔ infer        1.0.5     ✔ workflows    1.1.3\n✔ modeldata    1.2.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.1     ✔ yardstick    1.2.0\n✔ recipes      1.0.9     \n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nRows: 212969 Columns: 86\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (14): iso_code, region_group, income_group, country, survey, level, cate...\ndbl (72): year, grade, comp_prim_v2_m, comp_lowsec_v2_m, comp_upsec_v2_m, co...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 249 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): name, alpha-2, alpha-3, iso_3166-2, region, sub-region, intermediat...\ndbl (4): country-code, region-code, sub-region-code, intermediate-region-code\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n`summarise()` has grouped output by 'iso_code'. You can override using the `.groups` argument.\n`summarise()` has grouped output by 'sub_region'. You can override using the `.groups` argument.\n`summarise()` has grouped output by 'sub_region'. You can override using the `.groups` argument.\n`summarise()` has grouped output by 'region'. You can override using the `.groups` argument.\n`summarise()` has grouped output by 'sub_region'. You can override using the `.groups` argument.\n`summarise()` has grouped output by 'sub_region'. You can override using the `.groups` argument.\n\n\nYou should never use absolute paths (eg. /Users/danielsussman/path/to/project/ or C:\\MA415\\\\Final_Project\\).\nYou might consider using the here function from the here package to avoid path problems.\n\n\nLoad and clean data script\nThe idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them. This file might create a derivative data set that you then use for your subsequent analysis. Note that you don’t need to run this script from every post/page. Instead, you can load in the results of this script, which could be plain text files or .RData files. In your data page you’ll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes. To link to this file, you can use [cleaning script](/scripts/load_and_clean_data.R) wich appears as cleaning script."
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones and summarize the rest.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your load_and_clean_data.R file.\nRrename variables and recode factors to make data more clear.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your load_and_clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained.\n\n\n\nData Background\nOur team utilized three main datasets for our analysis: Country Mapping - ISO, Continent, Region: This dataset was obtained from Kaggle, a platform offering a wide range of free data resources. It was created for mapping countries in the dataset creator’s analysis, and she permits its free use. The variables in this dataset are straightforward, naming countries with their ISO codes and categorizing them into different continents, regions, and sub-regions. For instance, Afghanistan is represented as AFG - Asia - Southern Asia. PISA Scores by Country 2024: Sourced from the World Population Review, this dataset is part of the Programme for International Student Assessment (PISA), coordinated by the Organisation for Economic Co-operation and Development (OECD). PISA assesses the educational performance of 15-year-old students across approximately 80 countries through a two-hour test focused on science, reading, and mathematics. The dataset provides average scores in these subjects, reflecting the educational standards and economic success indicators of the participating countries. World Inequality Database on Education (WIDE): Available at the World Inequality Database on Education, the WIDE database compiles data from various reliable surveys and assessments, offering insights into the impact of different inequality factors on educational outcomes. Its goal is to highlight significant educational disparities across and within countries to aid in policy-making and public discourse.\nThe following are the relevant variables for the chosen dataset. name: Names of the country.\nregion: The continent in which the country is located.\nsub-region: The specific region of the continent in which the country is located.\nOverallPisaScore2022: Total Pisa scores of the country in 2022.\nPISAScoresMathScore2022: The Pisa scores in math of the country in 2022.\nPISAScoresScienceScore2022: The Pisa scores in science of the country in 2022.\nPISAScoresReadingScore2022: The Pisa scores in reading of the country in 2022.\nliteracy_1524_no: Percentage of young people aged 15‐24 who can read a simple sentence.\ncomp_prim_v2_m: Percentage of (i) children and young people aged 3‐5 years above primary school graduation age and (ii) young people aged 15‐24 years, who have completed primary school.\nmlevel1_m : Passing rate of Level 1 Math Test.\nmlevel2_m: Passing rate of Level 2 Math Test.\nmlevel3_m: Passing rate of Level 3 Math Test.\neduyears_2024_m: Average number of years of schooling attained for the age group 20–24 years.\neduout_prim_m: Percentage of children of primary school age who are not in school.\ncomp_lowsec_v2_m: Percentage of (i) young people aged 3‐5 years above lower secondary school graduation age and (ii) young people aged 15‐24 years, who have completed lower secondary school.\npreschool_3_no: Percentage of 3 to 4 year olds attending any type of pre–primary education programme.\n\n\nData loading and grouping\nclean_script\nThe libraries we use:\n\nlibrary(tidyverse)\n#A collection of packages for data manipulation and visualization.\nlibrary(tidymodels)\n#A A suite for modern and tidy statistical modeling.\nlibrary(broom) \n#Converts statistical analysis objects into tidy format.\nlibrary(scales) \n# For formatting and manipulating axis labels and color scales in plots.\nlibrary(patchwork) \n#Facilitates the combination of multiple ggplot2 plots into one.\nlibrary(knitr) \n#Enables dynamic report generation integrating R code with text.\nlibrary(stringr)\n#Provides easy-to-use functions for string operations.\nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n# Offers tools for regression diagnostics and other statistical tests.\nlibrary(caret)\n\nLoading required package: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\n# Focuses on training and tuning machine learning models.\nlibrary(ggplot2)\n# Implements a grammar of graphics for creating plots.\nlibrary(dplyr)\n#Streamlines data manipulation tasks.\nlibrary(readxl)\n#Allows for reading Excel files into R.\nlibrary(MLmetrics)\n\n\nAttaching package: 'MLmetrics'\n\n\nThe following objects are masked from 'package:caret':\n\n    MAE, RMSE\n\n\nThe following object is masked from 'package:base':\n\n    Recall\n\n# Contains functions for computing machine learning metrics.\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n#Extends ggplot2 for creating complex visualizations easily.\n\nTo enhance our data preparation process, we plan to refine the regional categorization within our dataset. Initially, we identified that the ‘region’ column unexpectedly amalgamated diverse regions, such as combining Europe with North America and East with Southeast Asia. To address this, we will adopt a strategy to split the data more accurately according to geographic regions. We have sourced an additional dataset that delineates regions and continents more distinctly. By integrating this new dataset with our original data, we will reorganize the regional variables for clearer segmentation. Following these adjustments, we will conduct data visualization on the newly grouped data. This step will facilitate a deeper understanding and provide clearer insights by representing the data in a visually intuitive manner. To enhance our data preparation process, we plan to refine the regional categorization within our dataset. Initially, we identified that the ‘region’ column unexpectedly amalgamated diverse regions, such as combining Europe with North America and East with Southeast Asia. To address this, we will adopt a strategy to split the data more accurately according to geographic regions. We have sourced an additional dataset that delineates regions and continents more distinctly. By integrating this new dataset with our original data, we will reorganize the regional variables for clearer segmentation. Following these adjustments, we will conduct data visualization on the newly grouped data. This step will facilitate a deeper understanding and provide clearer insights by representing the data in a visually intuitive manner.\n\ndata &lt;- read_csv('dataset/educ.csv')\n\nRows: 212969 Columns: 86\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (14): iso_code, region_group, income_group, country, survey, level, cate...\ndbl (72): year, grade, comp_prim_v2_m, comp_lowsec_v2_m, comp_upsec_v2_m, co...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncontinent &lt;- read_csv('dataset/continents2.csv')\n\nRows: 249 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): name, alpha-2, alpha-3, iso_3166-2, region, sub-region, intermediat...\ndbl (4): country-code, region-code, sub-region-code, intermediate-region-code\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npisa &lt;- read_csv('dataset/pisa-scores-by-country-2024.csv', show_col_types = FALSE)\n\nWe try to merge PISA and region dataset, so it can allow us for exploring how educational outcomes vary across different regions, and we can analyse the influence of regional contexts on educational difference with data."
  },
  {
    "objectID": "big_picture.html#what-did-we-find",
    "href": "big_picture.html#what-did-we-find",
    "title": "Big Picture",
    "section": "What did we find?",
    "text": "What did we find?\n\nAfrica was the worst perfromer by almost every metric\nWe looked at many metrics that all aim to measure the education level of a country in some capacity. This includes PISA scores, literacy rates, primary school completion rate, mean years of education, etc. What we noticed in essentially all of these metrics that Africa was the worst performer in every category. However, the concerning part is that it was not even close. Africa consistently lagged behind the rest of the continents.\n\n\nWhile Africa is the worst performer, Nortern Africa is performing a lot better than Sub-Saharan Africa.\nWhen analyzing the primary school completion rate for Africa as a continent, we found that as the worst performer by far. But when we took a deeper dive, we found that Northern Africa was actually on par with the rest of the world in terms of this metric, where as Sub-Saharan Africa significantly lagged behind the rest of the world. This is true for many other metrics as well.\n\n\n\n\n\n\n\n\n\n\nSo what does this mean? Common perception tells us that Africa as a continent is behind in education, but that statement is only partially correct. When breaking down these metrics by region rather than continent, we can tell that This is more of a Sub-Saharan African issue rather than an African issue. Many countries in Africa, such as Nauru (NER), Chad (TCD), and Libera (LBR), have less than 25% of their kids complete primary school, which is a shockingly low number. Rather than labeling Africa continent that is behind in terms of quality education, we should be more-so focusing on Sub-Saharan Africa as a region that needs better education.\n\n\nKeep your kids in school at all costs\nMuch of our analysis was focused on metrics involved with staying in school. Metrics such as primary school completion rate, mean years of education, percentage of people not in school, etc, all fall into this category. We have also analyzed benchmark metrics such as academic achievement, literacy rates, and PISA scores. Our analysis makes it clear that there is an extremely strong correlation between these schooling metrics such as primary school completion rate and mean years of education, and the benchmark metrics such as PISA scores and literacy rates.\n\n\n\n\n\nSo what does this mean? This plot tells us that how long you stay in school is directly correlated with a benchmark metric such as literacy rate. The number one most important thing when it comes to school is that you are at least attending school. Of course doing well and getting good grades should be a big goal too, but attending school in the first place is extremely important.\n\n\nEurope is doing a great job and the world should model after them\nOn the other side of things, we noticed that Europe was the best performing continent in almost every metric. The suprising part is that Europe Europe does not really have any countries that are significantly behind any other countires. In section 1.6 of our analysis, we looked at the worst 3 countries in each continent for each metric, and Europe’s “worst” countries still outperformed the average countries in other continents. For example, when analyzing the primary school completion rate, the country with the lowest completion rate in Europe, Albania, still had a rate of 0.97, which is significantly higher than every other country in that table.\nSo what does this mean? This tells us that the world could benefit form modeling its education systems after Europe. European education systems typically receive substantial government funding, which ensures high quality teaching and resources."
  },
  {
    "objectID": "analysis.html#section-2.1-model1",
    "href": "analysis.html#section-2.1-model1",
    "title": "Analysis",
    "section": "Section 2.1: Model1",
    "text": "Section 2.1: Model1\nHypothesis 1: Factors that will affect the lower secondary school completion rate: primary school completion rate_v2(young people who are 3-5 ages above the normal primary graduation age[prolly neagtively affect the lower secondary school completion rate]), big_region, wealth, gender, and Urbanicity\nExpectation: comp_prim_v2_m will positively affect comp_lowsec_v2_m. In region of Africa, the area of rural, the gender of female, or the quintile 1 in Wealth will negatively affect comp_lowsec_v2_m.\n-Continuous variable: comp_prim_v2_m\n-Categorical variable: wealth(by level 1-5), sex(female/male), region(by continents), Location(=urbanicity by rural/urban)\n\nOriginal Model1\n\n\n\nCall:\nlm(formula = comp_lowsec_v2_m ~ as.factor(region) + as.factor(Location) + \n    as.factor(Sex) + as.factor(Wealth) + comp_prim_v2_m, data = Location_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.67342 -0.07977  0.02010  0.09152  0.39425 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    -0.232695   0.007489 -31.070  &lt; 2e-16 ***\nas.factor(region)Asia           0.092947   0.006050  15.362  &lt; 2e-16 ***\nas.factor(region)Europe         0.198130   0.014221  13.933  &lt; 2e-16 ***\nas.factor(region)North America  0.011440   0.007802   1.466 0.142649    \nas.factor(region)Oceania        0.143052   0.037197   3.846 0.000122 ***\nas.factor(region)South America  0.140285   0.007011  20.010  &lt; 2e-16 ***\nas.factor(Location)Urban        0.020791   0.004415   4.710 2.57e-06 ***\nas.factor(Sex)Male              0.003602   0.004164   0.865 0.387033    \nas.factor(Wealth)Quintile 2     0.002351   0.007122   0.330 0.741322    \nas.factor(Wealth)Quintile 3     0.009989   0.007108   1.405 0.160043    \nas.factor(Wealth)Quintile 4     0.040039   0.007209   5.554 2.99e-08 ***\nas.factor(Wealth)Quintile 5     0.096784   0.007521  12.869  &lt; 2e-16 ***\ncomp_prim_v2_m                  0.940660   0.010707  87.856  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1273 on 3726 degrees of freedom\n  (28612 observations deleted due to missingness)\nMultiple R-squared:  0.853, Adjusted R-squared:  0.8525 \nF-statistic:  1802 on 12 and 3726 DF,  p-value: &lt; 2.2e-16\n\n\n                        GVIF Df GVIF^(1/(2*Df))\nas.factor(region)   1.683944  5        1.053496\nas.factor(Location) 1.124812  1        1.060572\nas.factor(Sex)      1.000401  1        1.000201\nas.factor(Wealth)   1.285657  4        1.031907\ncomp_prim_v2_m      1.931383  1        1.389742\n\n\n\n\n\n\n\n\nThe residuals plot does not seem randomly distributed, so we decide to do some transformations on the variables to meet the assumptions of normality.\n\n\nNormality and Transformation\nWe have tried to make the transformation on the response variable which does not seem normally distributed because, based on the left plot, the distribution left skewed severely. After different trials on the response variable, we finally applied the square root arcsine transformation, and we got the approximately normal histogram, shown by the right side of the plot.\n\n\nModel after Transformation\n\n\n\nCall:\nlm(formula = asin(sqrt(Location_data$comp_lowsec_v2_m)) ~ as.factor(region) + \n    as.factor(Location) + as.factor(Wealth) + as.factor(Sex) + \n    comp_prim_v2_m, data = Location_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.78259 -0.10385  0.01225  0.10890  0.50532 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    -0.133804   0.009522 -14.052  &lt; 2e-16 ***\nas.factor(region)Asia           0.122669   0.007692  15.947  &lt; 2e-16 ***\nas.factor(region)Europe         0.345051   0.018080  19.085  &lt; 2e-16 ***\nas.factor(region)North America  0.018736   0.009920   1.889 0.058995 .  \nas.factor(region)Oceania        0.170825   0.047292   3.612 0.000308 ***\nas.factor(region)South America  0.174104   0.008913  19.533  &lt; 2e-16 ***\nas.factor(Location)Urban        0.031223   0.005613   5.563 2.84e-08 ***\nas.factor(Wealth)Quintile 2     0.006059   0.009055   0.669 0.503466    \nas.factor(Wealth)Quintile 3     0.017626   0.009038   1.950 0.051220 .  \nas.factor(Wealth)Quintile 4     0.055694   0.009166   6.076 1.35e-09 ***\nas.factor(Wealth)Quintile 5     0.132178   0.009562  13.824  &lt; 2e-16 ***\nas.factor(Sex)Male              0.007044   0.005294   1.331 0.183381    \ncomp_prim_v2_m                  1.167443   0.013613  85.762  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1618 on 3726 degrees of freedom\n  (28612 observations deleted due to missingness)\nMultiple R-squared:  0.8514,    Adjusted R-squared:  0.8509 \nF-statistic:  1779 on 12 and 3726 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nAfter applying Arcsine Square Root transformation on the model, we made the square root of the standardized residuals plot to see if it met the assumption of homoscedasticity, which indeed improved a lot.\n\n\nSection 2.1.1: Model1 Formula\nasin(sqrt(Location_data$comp_lowsec_v2_m)) = b0 + b1 x region(Africa vs Asia) + b2 x region(Africa vs Europe) + b3 x region(Africa vs Oceania) + b3 x region(Africa vs South America) + b4 x Location(urban vs rural) + b5 x Wealth(Quintile 1 vs Quintile 4) + b6 x Wealth(Quintile 1 vs Quintile 5) + b7 x comp_prim_v2_m\n\n\nSection 2.1.2: Model1 Result Analysis\nResult Analysis:\n1) The model’s intercept is negative, suggesting that the baseline group for region, location, sex, and wealth has a negative association with the completion rate for lower secondary education.\n2) The region variable has several levels. Compared to the baseline of Africa as the reference category, all other regions (Asia, Europe, North America, Oceania, South America) show a positive association with lower secondary completion rates. To explain the association toward the response variable, I will provide an example. For the coefficient of 0.123 for Asia: This means that, compared to Africa, being in the region of Asia is associated with an average increase in the lower secondary completion rates by 0.123 units. Since the region of Africa is the baseline, and its association with all other region is positive, so we can conclude that being in Africa will have the lowest lower-secondary completion rate compared to other regions. And the significance is indicated by the p-value that is smaller than 0.05.\n3) Urban locations have a positive coefficient, indicating that being in an urban location is associated with higher secondary completion rates compared to rural locations.\n4) Sex does not seem to be a significant predictor, as the coefficient for males is small and not statistically significant (p-value &gt; 0.05).\n5) Wealth shows a strong positive association with lower secondary completion. As wealth quintiles increase, there’s a corresponding significant increase in the completion rates, with the highest quintile (Quintile 5) having the largest coefficient.\n6) The comp_prim_v2_m variable has a large positive coefficient, indicating a strong association with higher rates of lower secondary completion.\n7) The adjusted R-squared is 0.8509, indicating a good fit even after adjusting for the number of predictors.\n8) The F-statistic is very high, and the associated p-value is less than 0.001, suggesting the model is statistically significant.\n\n\nSection 2.1.3: Model1 Conclusion\nThe R-squared is 0.8509, and the vif shows that there is no collinearity between predictors. We will remove the predictor of “sex” from the mode because of insignificance indicated by p-value higher than 0.05. Finally, being in the region of Africa, being in the location of rural area, and staying in the lower wealth level will negatively influence the secondary education completion. And the high primary education completion will positively affect the secondary education completion rate."
  },
  {
    "objectID": "analysis.html#section-2.2-model2",
    "href": "analysis.html#section-2.2-model2",
    "title": "Analysis",
    "section": "Section 2.2: Model2",
    "text": "Section 2.2: Model2\nHypothesis 2: Factors that will affect literacy_1524_m (Percentage of young people aged 15‐24 who can read a simple sentence): comp_prim_1524_no (# of young people aged 15-24 completed primary school), preschool_3_no (# of 3 to 4 year olds attending any type of pre–primary education programme), region, wealth.\nExpectation: The predictors of either comp_prim_1524_no or preschool_3_no will negatively affect literacy_1524_m. Urban region will increase literacy_1524_m, and higher level of wealth will postively affect the literacy_1524_m as well.\n-Continuous variable: comp_prim_1524_no, preschool_3_no\n-Categorical variable: wealth(by level 1-5), region(by continents)\n\nOriginal Model 2\n\n\n\nCall:\nlm(formula = literacy_1524_no ~ as.factor(region) + as.factor(Wealth) + \n    edu2_2024_no + preschool_3_no, data = Location_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1903.48  -298.65   -34.83   212.14  3111.19 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    -176.8065    82.7822  -2.136 0.033193 *  \nas.factor(region)Asia           514.8999    62.2549   8.271 1.28e-15 ***\nas.factor(region)Europe         616.8468    78.5480   7.853 2.61e-14 ***\nas.factor(region)North America  253.9103   101.4412   2.503 0.012640 *  \nas.factor(region)South America   68.7070   107.2218   0.641 0.521958    \nas.factor(Wealth)Quintile 2      44.1101    83.1961   0.530 0.596219    \nas.factor(Wealth)Quintile 3     158.7777    83.1703   1.909 0.056841 .  \nas.factor(Wealth)Quintile 4     301.1526    85.1746   3.536 0.000446 ***\nas.factor(Wealth)Quintile 5     701.4635    90.5896   7.743 5.65e-14 ***\nedu2_2024_no                      2.2464     0.1267  17.728  &lt; 2e-16 ***\npreschool_3_no                    0.6760     0.1764   3.832 0.000144 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 559.2 on 487 degrees of freedom\n  (31853 observations deleted due to missingness)\nMultiple R-squared:  0.7265,    Adjusted R-squared:  0.7208 \nF-statistic: 129.3 on 10 and 487 DF,  p-value: &lt; 2.2e-16\n\n\n                      GVIF Df GVIF^(1/(2*Df))\nas.factor(region) 1.261002  4        1.029413\nas.factor(Wealth) 1.214545  4        1.024594\nedu2_2024_no      2.415127  1        1.554068\npreschool_3_no    2.405951  1        1.551113\n\n\n\n\n\n\n\n\n\n\nNormality and Transformation\n\n\n\n\n\nWe decided to apply a logarithmic transformation to the response variable to achieve a more normal distribution in the histogram. This transformation significantly improved the original distribution, which was severely right-skewed. After the transformation, the data exhibited a more normal distribution, as evidenced by the more evenly distributed frequencies.\n\n\nModel 2 After Log Transformation\n\n\n\nCall:\nlm(formula = literacy_1524_no ~ as.factor(region) + as.factor(Wealth) + \n    edu2_2024_no + preschool_3_no, data = Location_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1903.48  -298.65   -34.83   212.14  3111.19 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    -176.8065    82.7822  -2.136 0.033193 *  \nas.factor(region)Asia           514.8999    62.2549   8.271 1.28e-15 ***\nas.factor(region)Europe         616.8468    78.5480   7.853 2.61e-14 ***\nas.factor(region)North America  253.9103   101.4412   2.503 0.012640 *  \nas.factor(region)South America   68.7070   107.2218   0.641 0.521958    \nas.factor(Wealth)Quintile 2      44.1101    83.1961   0.530 0.596219    \nas.factor(Wealth)Quintile 3     158.7777    83.1703   1.909 0.056841 .  \nas.factor(Wealth)Quintile 4     301.1526    85.1746   3.536 0.000446 ***\nas.factor(Wealth)Quintile 5     701.4635    90.5896   7.743 5.65e-14 ***\nedu2_2024_no                      2.2464     0.1267  17.728  &lt; 2e-16 ***\npreschool_3_no                    0.6760     0.1764   3.832 0.000144 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 559.2 on 487 degrees of freedom\n  (31853 observations deleted due to missingness)\nMultiple R-squared:  0.7265,    Adjusted R-squared:  0.7208 \nF-statistic: 129.3 on 10 and 487 DF,  p-value: &lt; 2.2e-16\n\n\n                      GVIF Df GVIF^(1/(2*Df))\nas.factor(region) 1.261002  4        1.029413\nas.factor(Wealth) 1.214545  4        1.024594\nedu2_2024_no      2.415127  1        1.554068\npreschool_3_no    2.405951  1        1.551113\n\n\n\n\n\n\n\n\nAfter Log Transformation on the y variable, the residual plots are more randomly distributed. And there is no multicollinearity. Thus, we will use this model as our final model.\n\n\nSection 2.2.1: Model2 Formula\nlog (literacy_1524_no) = b0 + b1 x region(Africa vs Asia) + b2 x region(Africa vs Europe) + b3 x region(Africa vs North America) + b4 x Wealth(Quintile 1 vs Quintile 4) + b5 x Wealth(Quintile 1 vs Quintile 5) + b6 x edu2_2024_no + b7 x preschool_3_no\n\n\nSection 2.2.2: Model2 Result Analysis\nResult Analysis:\n1) For the region variable: Asia has a positive coefficient (514.8999), meaning that, compared to the Africa region, it is associated with an increase in the dependent variable. Europe has an even higher positive coefficient (616.8468), indicating a stronger association compared to the Africa region than Asia. North America and South America also have positive coefficients, but the impact is less compared to Asia and Europe. The coefficients for regions are statistically significant except for South America (p-value &gt; 0.05).\n2) Wealth quintiles show a gradient of increasing positive coefficients from Quintile 2 to Quintile 5, suggesting that as wealth increases, the dependent variable also increases. Quintile 5 has a particularly high coefficient, and the effects for Quintile 4 and Quintile 5 are statistically significant (p &lt; 0.01).\n3) The variable edu2_2024_no has a very high positive coefficient (2424.4635), indicating a strong and statistically significant association with the dependent variable.\n4) The preschool variable (preschool_3_no) has a small but statistically significant positive coefficient, indicating that an increase in this variable is associated with an increase in the dependent variable.\n5) The model has a relatively high R-squared value of 0.7265, meaning approximately 72.65% of the variance in the dependent variable is explained by the model, indicating a good fit.\n6) The F-statistic is very large, and the p-value is less than 0.001, suggesting that the model is highly statistically significant.\n\n\nSection 2.2.3: Model2 Conclusion\nThe R-squared is 0.7208, and the vif shows that there is no collinearity between predictors. We will remove the predictors that have the insignificance indicated by p-value higher than 0.05 from the model. In summary, being in the region of Africa and South America, or staying in the lower wealth level will negatively influence the secondary education completion. And the higher rate of attending pre-primary institution will positively affect the secondary education completion rate. However, an interetsing finding is that less than two years schooling can also increase the percentage of young people aged 15‐24 who can read a simple sentence. We could conduct further analysis on this relationship."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 7, 2024 at 11:59pm.\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nPost 6\n\n\n\n\n\n1111\n\n\n\n\n\n\nApr 22, 2024\n\n\nTeam 4\n\n\n\n\n\n\n  \n\n\n\n\nPost 5\n\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2024\n\n\nTeam 4\n\n\n\n\n\n\n  \n\n\n\n\nPost 4\n\n\n\n\n\nPOST 4\n\n\n\n\n\n\nApr 8, 2024\n\n\nTeam 4\n\n\n\n\n\n\n  \n\n\n\n\nPost 3\n\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2024\n\n\nTeam 4\n\n\n\n\n\n\n  \n\n\n\n\nPost 2\n\n\n\n\n\n\n\n\n\n\n\n\nMar 24, 2024\n\n\nTeam 4\n\n\n\n\n\n\n  \n\n\n\n\nTeam 4 three datasets\n\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2024\n\n\nTeam 4\n\n\n\n\n\n\n  \n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n  \n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post.\n\n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n  \n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting.\n\n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-04-01-post-3/post-3.html",
    "href": "posts/2024-04-01-post-3/post-3.html",
    "title": "Post 3",
    "section": "",
    "text": "Data Visualizing Approach\nAfter cleaning/grouping the data, we took a deeper look to understand the data set by visualized the data in different graph to catch the pattern.\n\nThis graph shows the proportion of people in NORTH AFRICA who have completed primary school. It is interesting how people in Urban areas have a slightly higher completion rate as I would expect people in urban areas to have a lower completion rate. It is also worth noting that the NA bar is near the proportion of the Rural bar which suggests that most of the NA probably would fall into the Rural bar.\n\nThis graph is the same as the one above but for SUB-SAHARAN AFRICA. Here, overall, the proportions are lower which implies that education in sub-saharan Africa is not as good as education in Northern Africa. Also, there is a bigger difference between the urban and rural bar here.\n\nThis graph shows the mean primary completion rate for all of the North African countries.\n\nThis graph shows the mean primary school completion rate of all sub-saharan African countries. \n\nThis shows the number of observations for each Latin American country. It is definitely worth noting that countries like LCA and BRB do not have nearly as much data as the other countries. This should be noted for the entirety of our project.\n\nThis is a quick linear regression model we made. There is a relatively strong linear relationships between mean education years for 20-24 year olds and the mean primary completion rate. Note that this is grouped by country. The r-square is 0.72999 which indicated our model relative strong.\n\nThis is a residual plot. The residuals are relatively randomly distributed around y= 0, which means our model is doing a pretty good job of fitting the data. However, it is definitely worth noting that this is an extremely simple 1 variable and our models will require a lot more fine-tuning when they get more advanced."
  },
  {
    "objectID": "posts/2024-04-22-post-6/post-6.html",
    "href": "posts/2024-04-22-post-6/post-6.html",
    "title": "Post 6",
    "section": "",
    "text": "1111111111"
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2024-03-24-post-2/post-2.html",
    "href": "posts/2024-03-24-post-2/post-2.html",
    "title": "Post 2",
    "section": "",
    "text": "The data originates from Demographic and Health Surveys (DHS), Multiple Indicator Cluster Surveys (MICS), and other national household surveys and learning assessments across over 170 countries.The data originates from Demographic and Health Surveys (DHS), Multiple Indicator Cluster Surveys (MICS), and other national household surveys and learning assessments across over 170 countries.The data was jointly maintained and developed by the Global Education Monitoring Report and the UNESCO Institute for Statistics through their partnership.when we are trying to look at the education data from the different regions grouped, such as North America and Europe, East and Southeast Asia… We thought the grouping was not reasonable because, for example, the education systems of North American and European countries are very different, and even the countries within the European continent have distinct education systems. Thus, we may consider regrouping the data by Country.\nFor the sample population, each sample represents the data of a community in a country, and the data about the education may be categorized by different categories such as ethnicity alone, location alone, and ethnicity & location combined. There are 50 categories in total so we are able to draw maps, charts, infographics and tables from the comprehensive dataset.As mentioned above, the data are collected to achieve the goal of SDG 4 and Target 4.5 which commit to eliminate all kinds of disparities in education and provide as equitable education opportunities as possible.\nThe organization assists international governments in investing in science and technology, developing science policies, and evaluating the ways scientific research can aid in a country’s development and sustainability practices.Thus, the dataset helps support all kinds of research, and it helps making policy decisions on education, technology and all related fields to achieve the goal."
  },
  {
    "objectID": "posts/2024-03-24-post-2/post-2.html#data-background",
    "href": "posts/2024-03-24-post-2/post-2.html#data-background",
    "title": "Post 2",
    "section": "",
    "text": "The data originates from Demographic and Health Surveys (DHS), Multiple Indicator Cluster Surveys (MICS), and other national household surveys and learning assessments across over 170 countries.The data originates from Demographic and Health Surveys (DHS), Multiple Indicator Cluster Surveys (MICS), and other national household surveys and learning assessments across over 170 countries.The data was jointly maintained and developed by the Global Education Monitoring Report and the UNESCO Institute for Statistics through their partnership.when we are trying to look at the education data from the different regions grouped, such as North America and Europe, East and Southeast Asia… We thought the grouping was not reasonable because, for example, the education systems of North American and European countries are very different, and even the countries within the European continent have distinct education systems. Thus, we may consider regrouping the data by Country.\nFor the sample population, each sample represents the data of a community in a country, and the data about the education may be categorized by different categories such as ethnicity alone, location alone, and ethnicity & location combined. There are 50 categories in total so we are able to draw maps, charts, infographics and tables from the comprehensive dataset.As mentioned above, the data are collected to achieve the goal of SDG 4 and Target 4.5 which commit to eliminate all kinds of disparities in education and provide as equitable education opportunities as possible.\nThe organization assists international governments in investing in science and technology, developing science policies, and evaluating the ways scientific research can aid in a country’s development and sustainability practices.Thus, the dataset helps support all kinds of research, and it helps making policy decisions on education, technology and all related fields to achieve the goal."
  },
  {
    "objectID": "posts/2024-03-24-post-2/post-2.html#data-loading-and-cleaning",
    "href": "posts/2024-03-24-post-2/post-2.html#data-loading-and-cleaning",
    "title": "Post 2",
    "section": "Data Loading and Cleaning:",
    "text": "Data Loading and Cleaning:\nTo enhance our data preparation process, we plan to refine the regional categorization within our dataset. Initially, we identified that the ‘region’ column unexpectedly amalgamated diverse regions, such as combining Europe with North America and East with Southeast Asia. To address this, we will adopt a strategy to split the data more accurately according to geographic regions. We have sourced an additional dataset that delineates regions and continents more distinctly. By integrating this new dataset with our original data, we will reorganize the regional variables for clearer segmentation. Following these adjustments, we will conduct data visualization on the newly grouped data. This step will facilitate a deeper understanding and provide clearer insights by representing the data in a visually intuitive manner. To enhance our data preparation process, we plan to refine the regional categorization within our dataset. Initially, we identified that the ‘region’ column unexpectedly amalgamated diverse regions, such as combining Europe with North America and East with Southeast Asia. To address this, we will adopt a strategy to split the data more accurately according to geographic regions. We have sourced an additional dataset that delineates regions and continents more distinctly. By integrating this new dataset with our original data, we will reorganize the regional variables for clearer segmentation. Following these adjustments, we will conduct data visualization on the newly grouped data. This step will facilitate a deeper understanding and provide clearer insights by representing the data in a visually intuitive manner."
  },
  {
    "objectID": "posts/2024-03-24-post-2/post-2.html#data-for-equity",
    "href": "posts/2024-03-24-post-2/post-2.html#data-for-equity",
    "title": "Post 2",
    "section": "Data for Equity:",
    "text": "Data for Equity:\nThe definition of beneficence in the “Principles for Advancing Equitable Data Practice”, basically call people in data processing to maximize benefits for all human beings and avoid causing harm. In our project, we want to discuss the relationship between race and education. Recognizing our topic is full of sensitivity and complexity, we will ensure our analysis is fair without reinforcing any stereotypes to some races and regions. In order to follow beneficence, we will be meticulous in how data is interpreted and presented, and avoid making incorrect or harmful interpretations. Our data set we chose actually aligns with the principles. For example, the original data can be accessed through the websites of the Global Education Monitoring Report and the UNESCO Institute for Statistics. The website is accessible for all communities and it follows the principle of justice: return data and research results to community members in a form they can use. Concurrently, it also meets transparency, because to adhere to this principle, it would entail providing comprehensive metadata and ensuring easy access to data documentation. However, our dataset encompasses numerous variables, not all of which are pertinent to our analysis.  The presence of superfluous information poses a risk of leading to incorrect conclusions or oversimplifications. Additionally, there may be challenges due to our limited capacity to fully analyze the breadth of data available. By acknowledging these limitations and proceeding with caution, we aim to uphold the principles throughout our research."
  },
  {
    "objectID": "posts/2024-04-08-post-4/post-4.html",
    "href": "posts/2024-04-08-post-4/post-4.html",
    "title": "Post 4",
    "section": "",
    "text": "After regrouping our data set, we want to take a deeper understanding of all the variables to make sure we can make correct decision when we perform variable selection. In our previous posts, we have only use simply region and elementary education level and building simple regression just to see whether the data make sense to us. After verifying the potential answer we will get, we also want to add our variable to help building the regression.\nOur analysis sought to reveal the mean years of education across different categorizations such as location (urban vs. rural), sex (male vs. female), and more. Utilizing ggplot2, we visualized these differences, which unveiled significant disparities. For instance, urban areas consistently showed higher educational attainment than rural counterparts, with Europe leading in educational years and Africa lagging behind."
  },
  {
    "objectID": "posts/2024-04-08-post-4/post-4.html#insights-and-implications",
    "href": "posts/2024-04-08-post-4/post-4.html#insights-and-implications",
    "title": "Post 4",
    "section": "Insights and Implications",
    "text": "Insights and Implications\nFrom our exploration, we found some insights:\n\nLocation Matters: Urban residents generally have access to better educational opportunities than rural ones.\nWealth’s Influence: Higher wealth correlates with longer education years, albeit with potential data collection biases in regions with sparse data.\nGender Disparities: A nuanced picture of education years by sex across different regions, indicating areas where policy could bridge gaps.\n\nTo further our understanding, we delved into regression analysis, examining the impact of various factors on education years. Simple linear regression gave way to multiple linear regression models, incorporating factors like wealth and location alongside primary school completion rates.\nmodel &lt;- lm(eduyears_2024_m ~ comp_prim_1524_m + Location + Wealth, data = merged_data)"
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2024-04-17-post-5/post-5.html",
    "href": "posts/2024-04-17-post-5/post-5.html",
    "title": "Post 5",
    "section": "",
    "text": "This week we found two datasets to merge our original dataset with.\n1.) The first data set that we are merging with is a dataset that includes more specific world regions. Our original dataset only contains 9 different regions (look at the data_example dataframe below). The dataset that we are merging with (named continent_example) contains 17 different regions, which makes our analysis more specified. The original dataset grouped Central and Southern Asia together, and the new dataset does not do this, which allows us to find more differences within countries. This dataset was found from this link: https://www.kaggle.com/datasets/andradaolteanu/country-mapping-iso-continent-region.\n2.) The second dataset that we are merging with is a PISA dataset that contains PISA scores from countries all over the world. PISA is a standardized exam that is taken all around the world. Knowing these scores will allow us to make more exciting and interesting models that may provide more insight into the disparties between countries. What is cool about this dataset is that it contains the overall PISA score, but also the breakdowns. For example, it contains each country’s overall score, as well as each country’s math, science, and reading score. The downside of this dataset is that it does not contain scores from African countries. This dataset was found from this link: https://www.oecd.org/pisa/data/.\nThese are the two datasets that we have merged our original datset; however, there are a few more datasets that we are considering. We want to merge our dataset with some sort of teacher salary dataset as that may provide some insight into why the PISA scores are the way they are. Additionaly, we want to add years to the PISA scores. We only included PISA scores from 2022, and it may be interesting to include PISA scores from specific years.\nhttps://www.kaggle.com/datasets/andradaolteanu/country-mapping-iso-continent-region\n\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(tidymodels))\nsuppressPackageStartupMessages(library(broom))\nsuppressPackageStartupMessages(library(scales))\n\ndata &lt;- read_csv('dataset/educ.csv')\n\nRows: 212969 Columns: 86\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (14): iso_code, region_group, income_group, country, survey, level, cate...\ndbl (72): year, grade, comp_prim_v2_m, comp_lowsec_v2_m, comp_upsec_v2_m, co...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncontinent &lt;- read_csv('dataset/continents2.csv')\n\nRows: 249 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): name, alpha-2, alpha-3, iso_3166-2, region, sub-region, intermediat...\ndbl (4): country-code, region-code, sub-region-code, intermediate-region-code\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npisa &lt;- read_csv('dataset/pisa-scores-by-country-2024.csv')\n\nRows: 81 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): country\ndbl (5): OverallPisaScore2022, PISAScoresMathScore2022, PISAScoresScienceSco...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata_example &lt;- data |&gt; group_by(region_group) |&gt; slice_head(n = 1) \ndata_example\n\n# A tibble: 8 × 86\n# Groups:   region_group [8]\n  iso_code region_group   income_group country survey  year level grade category\n  &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;   \n1 AFG      Central and S… Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Ethnici…\n2 CHN      Eastern and S… Upper middl… China   CFPS    2010 &lt;NA&gt;     NA Ethnici…\n3 ALB      Europe and No… Upper middl… Albania DHS     2009 &lt;NA&gt;     NA Ethnici…\n4 ARG      Latin America… Upper middl… Argent… EPH     2004 &lt;NA&gt;     NA Region  \n5 ARE      Northern Afri… High income… U. A. … PIRLS   2011 Prim…     4 Location\n6 AUS      Oceania        High income… Austra… HES-S…  2010 &lt;NA&gt;     NA Ethnici…\n7 AGO      Sub-Saharan A… Lower middl… Angola  DHS     2015 &lt;NA&gt;     NA Location\n8 &lt;NA&gt;     &lt;NA&gt;           Low income … &lt;NA&gt;    &lt;NA&gt;      NA &lt;NA&gt;     NA Total   \n# ℹ 77 more variables: Sex &lt;chr&gt;, Location &lt;chr&gt;, Wealth &lt;chr&gt;, Region &lt;chr&gt;,\n#   Ethnicity &lt;chr&gt;, Religion &lt;chr&gt;, Language &lt;chr&gt;, comp_prim_v2_m &lt;dbl&gt;,\n#   comp_lowsec_v2_m &lt;dbl&gt;, comp_upsec_v2_m &lt;dbl&gt;, comp_prim_1524_m &lt;dbl&gt;,\n#   comp_lowsec_1524_m &lt;dbl&gt;, comp_upsec_2029_m &lt;dbl&gt;, eduyears_2024_m &lt;dbl&gt;,\n#   edu2_2024_m &lt;dbl&gt;, edu4_2024_m &lt;dbl&gt;, eduout_prim_m &lt;dbl&gt;,\n#   eduout_lowsec_m &lt;dbl&gt;, eduout_upsec_m &lt;dbl&gt;, comp_prim_v2_no &lt;dbl&gt;,\n#   comp_lowsec_v2_no &lt;dbl&gt;, comp_upsec_v2_no &lt;dbl&gt;, comp_prim_1524_no &lt;dbl&gt;, …\n\ncontinent_example &lt;- continent |&gt; group_by(`sub-region`) |&gt; slice_head(n=1)\ncontinent_example\n\n# A tibble: 18 × 11\n# Groups:   sub-region [18]\n   name      `alpha-2` `alpha-3` `country-code` `iso_3166-2` region `sub-region`\n   &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;  &lt;chr&gt;       \n 1 Australia AU        AUS                   36 ISO 3166-2:… Ocean… Australia a…\n 2 Kazakhst… KZ        KAZ                  398 ISO 3166-2:… Asia   Central Asia\n 3 China     CN        CHN                  156 ISO 3166-2:… Asia   Eastern Asia\n 4 Belarus   BY        BLR                  112 ISO 3166-2:… Europe Eastern Eur…\n 5 Anguilla  AI        AIA                  660 ISO 3166-2:… Ameri… Latin Ameri…\n 6 Fiji      FJ        FJI                  242 ISO 3166-2:… Ocean… Melanesia   \n 7 Guam      GU        GUM                  316 ISO 3166-2:… Ocean… Micronesia  \n 8 Algeria   DZ        DZA                   12 ISO 3166-2:… Africa Northern Af…\n 9 Bermuda   BM        BMU                   60 ISO 3166-2:… Ameri… Northern Am…\n10 Åland Is… AX        ALA                  248 ISO 3166-2:… Europe Northern Eu…\n11 American… AS        ASM                   16 ISO 3166-2:… Ocean… Polynesia   \n12 Brunei D… BN        BRN                   96 ISO 3166-2:… Asia   South-easte…\n13 Afghanis… AF        AFG                    4 ISO 3166-2:… Asia   Southern As…\n14 Albania   AL        ALB                    8 ISO 3166-2:… Europe Southern Eu…\n15 Angola    AO        AGO                   24 ISO 3166-2:… Africa Sub-Saharan…\n16 Armenia   AM        ARM                   51 ISO 3166-2:… Asia   Western Asia\n17 Austria   AT        AUT                   40 ISO 3166-2:… Europe Western Eur…\n18 Antarcti… AQ        ATA                   10 ISO 3166-2:… &lt;NA&gt;   &lt;NA&gt;        \n# ℹ 4 more variables: `intermediate-region` &lt;chr&gt;, `region-code` &lt;dbl&gt;,\n#   `sub-region-code` &lt;dbl&gt;, `intermediate-region-code` &lt;dbl&gt;\n\n\n\ncontinent &lt;- continent |&gt;\n  rename(\n    country = name,\n    sub_region = `sub-region`\n  )\n\n#continent\nmerged_data &lt;- merge(data, continent, by = \"country\")\nmerged_data2 &lt;- merge(merged_data, pisa, by = \"country\")\nhead(pisa)\n\n# A tibble: 6 × 6\n  country     OverallPisaScore2022 PISAScoresMathScore2…¹ PISAScoresScienceSco…²\n  &lt;chr&gt;                      &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1 China                       1605                    552                    543\n2 United Sta…                 1468                    465                    499\n3 Indonesia                   1108                    366                    383\n4 Brazil                      1192                    379                    403\n5 Mexico                      1220                    395                    410\n6 Japan                       1599                    536                    547\n# ℹ abbreviated names: ¹​PISAScoresMathScore2022, ²​PISAScoresScienceScore2022\n# ℹ 2 more variables: PISAScoresReadingScore2022 &lt;dbl&gt;,\n#   PISAScoresOverallScore2018 &lt;dbl&gt;\n\nhead(merged_data)\n\n      country iso_code              region_group         income_group survey\n1 Afghanistan      AFG Central and Southern Asia Low income countries   MICS\n2 Afghanistan      AFG Central and Southern Asia Low income countries    DHS\n3 Afghanistan      AFG Central and Southern Asia Low income countries    DHS\n4 Afghanistan      AFG Central and Southern Asia Low income countries    DHS\n5 Afghanistan      AFG Central and Southern Asia Low income countries    DHS\n6 Afghanistan      AFG Central and Southern Asia Low income countries   MICS\n  year level grade              category    Sex Location     Wealth    Region\n1 2011  &lt;NA&gt;    NA Sex & Wealth & Region Female     &lt;NA&gt; Quintile 4 Region CH\n2 2015  &lt;NA&gt;    NA       Wealth & Region   &lt;NA&gt;     &lt;NA&gt; Quintile 2   Helmand\n3 2015  &lt;NA&gt;    NA          Sex & Region   Male     &lt;NA&gt;       &lt;NA&gt;  Kandahar\n4 2015  &lt;NA&gt;    NA Sex & Wealth & Region Female     &lt;NA&gt; Quintile 5    Ghazni\n5 2015  &lt;NA&gt;    NA Sex & Wealth & Region   Male     &lt;NA&gt; Quintile 3   Jawzjan\n6 2011  &lt;NA&gt;    NA Sex & Wealth & Region Female     &lt;NA&gt; Quintile 3  Region N\n  Ethnicity Religion Language comp_prim_v2_m comp_lowsec_v2_m comp_upsec_v2_m\n1      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;         0.5761           0.2988          0.1509\n2      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;         0.3533           0.1675          0.1572\n3      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;         0.4692           0.2788          0.1677\n4      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;         0.7914           0.6618              NA\n5      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;         0.8165               NA              NA\n6      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;         0.2880           0.0678          0.0211\n  comp_prim_1524_m comp_lowsec_1524_m comp_upsec_2029_m eduyears_2024_m\n1           0.4383             0.3015            0.1290              NA\n2           0.2763             0.1727            0.0666          2.4788\n3           0.3768             0.2165            0.1139          3.2615\n4           0.5969             0.4152            0.1773          2.7868\n5           0.8459             0.6850            0.4035              NA\n6           0.1653             0.0720            0.0063              NA\n  edu2_2024_m edu4_2024_m eduout_prim_m eduout_lowsec_m eduout_upsec_m\n1          NA          NA            NA              NA             NA\n2      0.7219      0.7396            NA              NA             NA\n3      0.6230      0.6530            NA              NA             NA\n4      0.7139      0.7139            NA              NA             NA\n5          NA          NA            NA              NA             NA\n6          NA          NA            NA              NA             NA\n  comp_prim_v2_no comp_lowsec_v2_no comp_upsec_v2_no comp_prim_1524_no\n1              70                60               39               195\n2             116                66               78               302\n3             254               197              176               703\n4              38                38               NA               111\n5              45                NA               NA                87\n6             121                99               64               340\n  comp_lowsec_1524_no comp_upsec_2029_no eduyears_2024_no edu2_2024_no\n1                 195                144               NA           NA\n2                 302                275              131          131\n3                 703                548              292          292\n4                 111                 73               39           39\n5                  87                 62               NA           NA\n6                 340                238               NA           NA\n  edu4_2024_no eduout_prim_no eduout_lowsec_no eduout_upsec_no preschool_3_m\n1           NA             NA               NA              NA            NA\n2          131             NA               NA              NA            NA\n3          292             NA               NA              NA            NA\n4           39             NA               NA              NA            NA\n5           NA             NA               NA              NA            NA\n6           NA             NA               NA              NA            NA\n  preschool_3_no preschool_1ybefore_m preschool_1ybefore_no edu0_prim_m\n1             NA                   NA                    NA          NA\n2             NA                   NA                    NA      0.4917\n3             NA                   NA                    NA      0.4670\n4             NA                   NA                    NA      0.0621\n5             NA                   NA                    NA      0.1411\n6             NA                   NA                    NA          NA\n  edu0_prim_no trans_prim_m trans_prim_no trans_lowsec_m trans_lowsec_no\n1           NA           NA            NA             NA              NA\n2          318       0.9143            56             NA              NA\n3          529       0.8899           173         0.8869              99\n4           64       0.9677            40         0.9592              32\n5           67       0.9420            46             NA              NA\n6           NA           NA            NA             NA              NA\n  comp_higher_2yrs_2529_m comp_higher_2yrs_2529_no comp_higher_4yrs_2529_m\n1                      NA                       NA                      NA\n2                       0                      147                       0\n3                       0                      258                       0\n4                       0                       39                       0\n5                       0                       32                       0\n6                      NA                       NA                      NA\n  comp_higher_4yrs_2529_no comp_higher_4yrs_3034_m comp_higher_4yrs_3034_no\n1                       NA                      NA                       NA\n2                      147                       0                       89\n3                      258                       0                      166\n4                       39                      NA                       NA\n5                       32                      NA                       NA\n6                       NA                      NA                       NA\n  attend_higher_1822_m attend_higher_1822_no overage2plus_m overage2plus_no\n1                   NA                    NA             NA              NA\n2               0.0490                   151         0.1347             229\n3               0.0836                   397         0.3825             455\n4               0.3522                    63         0.1203              72\n5               0.2364                    47         0.2538              81\n6                   NA                    NA             NA              NA\n  literacy_1524_m literacy_1524_no mlevel1_m mlevel1_no rlevel1_m rlevel1_no\n1              NA               NA        NA         NA        NA         NA\n2          0.4960              102        NA         NA        NA         NA\n3          0.5592              111        NA         NA        NA         NA\n4          0.5360               31        NA         NA        NA         NA\n5              NA               NA        NA         NA        NA         NA\n6              NA               NA        NA         NA        NA         NA\n  slevel1_m slevel1_no mlevel2_m mlevel2_no rlevel2_m rlevel2_no slevel2_m\n1        NA         NA        NA         NA        NA         NA        NA\n2        NA         NA        NA         NA        NA         NA        NA\n3        NA         NA        NA         NA        NA         NA        NA\n4        NA         NA        NA         NA        NA         NA        NA\n5        NA         NA        NA         NA        NA         NA        NA\n6        NA         NA        NA         NA        NA         NA        NA\n  slevel2_no mlevel3_m mlevel3_no rlevel3_m rlevel3_no slevel3_m slevel3_no\n1         NA        NA         NA        NA         NA        NA         NA\n2         NA        NA         NA        NA         NA        NA         NA\n3         NA        NA         NA        NA         NA        NA         NA\n4         NA        NA         NA        NA         NA        NA         NA\n5         NA        NA         NA        NA         NA        NA         NA\n6         NA        NA         NA        NA         NA        NA         NA\n  mlevel4_m mlevel4_no rlevel4_m rlevel4_no slevel4_m slevel4_no alpha-2\n1        NA         NA        NA         NA        NA         NA      AF\n2        NA         NA        NA         NA        NA         NA      AF\n3        NA         NA        NA         NA        NA         NA      AF\n4        NA         NA        NA         NA        NA         NA      AF\n5        NA         NA        NA         NA        NA         NA      AF\n6        NA         NA        NA         NA        NA         NA      AF\n  alpha-3 country-code    iso_3166-2 region    sub_region intermediate-region\n1     AFG            4 ISO 3166-2:AF   Asia Southern Asia                &lt;NA&gt;\n2     AFG            4 ISO 3166-2:AF   Asia Southern Asia                &lt;NA&gt;\n3     AFG            4 ISO 3166-2:AF   Asia Southern Asia                &lt;NA&gt;\n4     AFG            4 ISO 3166-2:AF   Asia Southern Asia                &lt;NA&gt;\n5     AFG            4 ISO 3166-2:AF   Asia Southern Asia                &lt;NA&gt;\n6     AFG            4 ISO 3166-2:AF   Asia Southern Asia                &lt;NA&gt;\n  region-code sub-region-code intermediate-region-code\n1         142              34                       NA\n2         142              34                       NA\n3         142              34                       NA\n4         142              34                       NA\n5         142              34                       NA\n6         142              34                       NA\n\nhead(merged_data2)\n\n  country iso_code                region_group                  income_group\n1 Albania      ALB Europe and Northern America Upper middle income countries\n2 Albania      ALB Europe and Northern America Upper middle income countries\n3 Albania      ALB Europe and Northern America Upper middle income countries\n4 Albania      ALB Europe and Northern America Upper middle income countries\n5 Albania      ALB Europe and Northern America Upper middle income countries\n6 Albania      ALB Europe and Northern America Upper middle income countries\n  survey year           level grade                category    Sex Location\n1    DHS 2009            &lt;NA&gt;    NA   Sex & Wealth & Region   Male     &lt;NA&gt;\n2   PISA 2009 Upper secondary    NA Location & Sex & Wealth Female    Urban\n3   PISA 2012 Upper secondary    NA Location & Sex & Wealth Female    Urban\n4    DHS 2009            &lt;NA&gt;    NA Location & Sex & Wealth Female    Urban\n5   MICS 2005            &lt;NA&gt;    NA            Sex & Region Female     &lt;NA&gt;\n6   MICS 2000            &lt;NA&gt;    NA                  Wealth   &lt;NA&gt;     &lt;NA&gt;\n      Wealth  Region Ethnicity Religion Language comp_prim_v2_m\n1 Quintile 4 Coastal      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;         1.0000\n2 Quintile 5    &lt;NA&gt;      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;             NA\n3 Quintile 2    &lt;NA&gt;      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;             NA\n4 Quintile 3    &lt;NA&gt;      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;         0.9721\n5       &lt;NA&gt;  Tirana      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;             NA\n6 Quintile 1    &lt;NA&gt;      &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;             NA\n  comp_lowsec_v2_m comp_upsec_v2_m comp_prim_1524_m comp_lowsec_1524_m\n1           0.7303              NA           0.9969             0.6819\n2               NA              NA               NA                 NA\n3               NA              NA               NA                 NA\n4           0.7413           0.367           0.9379             0.4985\n5               NA              NA               NA                 NA\n6               NA              NA               NA                 NA\n  comp_upsec_2029_m eduyears_2024_m edu2_2024_m edu4_2024_m eduout_prim_m\n1            0.5380         11.2648      0.0000      0.0000        0.1064\n2                NA              NA          NA          NA            NA\n3                NA              NA          NA          NA            NA\n4            0.3462          8.7861      0.0681      0.0681        0.0298\n5                NA              NA      0.0000      0.0000            NA\n6                NA              NA      0.0000      0.0000            NA\n  eduout_lowsec_m eduout_upsec_m comp_prim_v2_no comp_lowsec_v2_no\n1          0.0117         0.3059              54                57\n2              NA             NA              NA                NA\n3              NA             NA              NA                NA\n4          0.0981         0.2145              93                53\n5              NA             NA              NA                NA\n6              NA             NA              NA                NA\n  comp_upsec_v2_no comp_prim_1524_no comp_lowsec_1524_no comp_upsec_2029_no\n1               NA               134                 134                 62\n2               NA                NA                  NA                 NA\n3               NA                NA                  NA                 NA\n4               53               190                 190                140\n5               NA                NA                  NA                 NA\n6               NA                NA                  NA                 NA\n  eduyears_2024_no edu2_2024_no edu4_2024_no eduout_prim_no eduout_lowsec_no\n1               37           37           37             71               68\n2               NA           NA           NA             NA               NA\n3               NA           NA           NA             NA               NA\n4               79           79           79            120              119\n5              172          172          172             NA               NA\n6              204          204          204             NA               NA\n  eduout_upsec_no preschool_3_m preschool_3_no preschool_1ybefore_m\n1              59            NA             NA                   NA\n2              NA            NA             NA                   NA\n3              NA            NA             NA                   NA\n4              80            NA             NA                   NA\n5              NA        0.3219             47                   NA\n6              NA            NA             NA                   NA\n  preschool_1ybefore_no edu0_prim_m edu0_prim_no trans_prim_m trans_prim_no\n1                    NA      0.0346           87       0.7042            67\n2                    NA          NA           NA           NA            NA\n3                    NA          NA           NA           NA            NA\n4                    NA      0.0394          135       0.7212            91\n5                    NA      0.0054          186           NA            NA\n6                    NA          NA           NA           NA            NA\n  trans_lowsec_m trans_lowsec_no comp_higher_2yrs_2529_m\n1         0.8422              37                      NA\n2             NA              NA                      NA\n3             NA              NA                      NA\n4         0.9644              41                  0.1093\n5             NA              NA                      NA\n6             NA              NA                      NA\n  comp_higher_2yrs_2529_no comp_higher_4yrs_2529_m comp_higher_4yrs_2529_no\n1                       NA                      NA                       NA\n2                       NA                      NA                       NA\n3                       NA                      NA                       NA\n4                       56                  0.0911                       56\n5                       NA                      NA                       NA\n6                       NA                      NA                       NA\n  comp_higher_4yrs_3034_m comp_higher_4yrs_3034_no attend_higher_1822_m\n1                  0.0604                       33               0.1049\n2                      NA                       NA                   NA\n3                      NA                       NA                   NA\n4                  0.0464                       74               0.1818\n5                      NA                       NA               0.1350\n6                      NA                       NA                   NA\n  attend_higher_1822_no overage2plus_m overage2plus_no literacy_1524_m\n1                    60         0.0366             123          0.9742\n2                    NA             NA              NA              NA\n3                    NA             NA              NA              NA\n4                    84         0.0955             213          0.9611\n5                   177         0.0126             146          0.9968\n6                    NA             NA              NA              NA\n  literacy_1524_no mlevel1_m mlevel1_no rlevel1_m rlevel1_no slevel1_m\n1              107        NA         NA        NA         NA        NA\n2               NA        NA         NA        NA         NA        NA\n3               NA        NA         NA        NA         NA        NA\n4              339        NA         NA        NA         NA        NA\n5              966        NA         NA        NA         NA        NA\n6               NA        NA         NA        NA         NA        NA\n  slevel1_no mlevel2_m mlevel2_no rlevel2_m rlevel2_no slevel2_m slevel2_no\n1         NA        NA         NA        NA         NA        NA         NA\n2         NA        NA         NA        NA         NA        NA         NA\n3         NA        NA         NA        NA         NA        NA         NA\n4         NA        NA         NA        NA         NA        NA         NA\n5         NA        NA         NA        NA         NA        NA         NA\n6         NA        NA         NA        NA         NA        NA         NA\n  mlevel3_m mlevel3_no rlevel3_m rlevel3_no slevel3_m slevel3_no mlevel4_m\n1        NA         NA        NA         NA        NA         NA        NA\n2        NA         NA        NA         NA        NA         NA        NA\n3        NA         NA        NA         NA        NA         NA        NA\n4        NA         NA        NA         NA        NA         NA        NA\n5        NA         NA        NA         NA        NA         NA        NA\n6        NA         NA        NA         NA        NA         NA        NA\n  mlevel4_no rlevel4_m rlevel4_no slevel4_m slevel4_no alpha-2 alpha-3\n1         NA        NA         NA        NA         NA      AL     ALB\n2         NA        NA         NA        NA         NA      AL     ALB\n3         NA        NA         NA        NA         NA      AL     ALB\n4         NA        NA         NA        NA         NA      AL     ALB\n5         NA        NA         NA        NA         NA      AL     ALB\n6         NA        NA         NA        NA         NA      AL     ALB\n  country-code    iso_3166-2 region      sub_region intermediate-region\n1            8 ISO 3166-2:AL Europe Southern Europe                &lt;NA&gt;\n2            8 ISO 3166-2:AL Europe Southern Europe                &lt;NA&gt;\n3            8 ISO 3166-2:AL Europe Southern Europe                &lt;NA&gt;\n4            8 ISO 3166-2:AL Europe Southern Europe                &lt;NA&gt;\n5            8 ISO 3166-2:AL Europe Southern Europe                &lt;NA&gt;\n6            8 ISO 3166-2:AL Europe Southern Europe                &lt;NA&gt;\n  region-code sub-region-code intermediate-region-code OverallPisaScore2022\n1         150              39                       NA                 1102\n2         150              39                       NA                 1102\n3         150              39                       NA                 1102\n4         150              39                       NA                 1102\n5         150              39                       NA                 1102\n6         150              39                       NA                 1102\n  PISAScoresMathScore2022 PISAScoresScienceScore2022 PISAScoresReadingScore2022\n1                     368                        376                        358\n2                     368                        376                        358\n3                     368                        376                        358\n4                     368                        376                        358\n5                     368                        376                        358\n6                     368                        376                        358\n  PISAScoresOverallScore2018\n1                         NA\n2                         NA\n3                         NA\n4                         NA\n5                         NA\n6                         NA\n\n\nWith this new data, we are able to make some new visualizations. For example, the following is a graph that shows the relative PISA scores for eahc Latin American Country.\n\n# Assuming merged_data is your original data frame\namericas_pisa_long &lt;- merged_data2 %&gt;%\n  filter(region == 'Americas') %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    pisa_overall_mean = mean(OverallPisaScore2022, na.rm = TRUE),\n    pisa_math_mean = mean(PISAScoresMathScore2022, na.rm = TRUE), # Assuming you meant Math Score here\n    pisa_science_mean = mean(PISAScoresScienceScore2022, na.rm = TRUE),\n    pisa_reading_mean = mean(PISAScoresReadingScore2022, na.rm = TRUE)\n  ) %&gt;%\n  pivot_longer(\n    cols = starts_with(\"pisa_\"),\n    names_to = \"score_type\",\n    values_to = \"score\"\n  ) %&gt;%\n  mutate(score_type = factor(score_type, levels = c(\"pisa_overall_mean\", \"pisa_math_mean\", \"pisa_science_mean\", \"pisa_reading_mean\")))\n\n# Creating the plot\namericas_pisa_plot &lt;- americas_pisa_long %&gt;%\n  ggplot(aes(x = country, y = score, fill = score_type)) + \n  geom_col(position = \"dodge\") + \n  scale_y_continuous(labels = label_comma()) + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(y = \"PISA Score\", x = \"Country\", fill = \"Score Type\") +\n  scale_fill_brewer(palette = \"Pastel1\") # Using a color palette for better visual distinction\n\namericas_pisa_plot\n\n\n\n\n\npisa_summary &lt;- merged_data2 |&gt;\n  group_by(country) |&gt;\n  summarise(\n    mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n    obs_primary_completion_rate = sum(!is.na(comp_prim_v2_m)),\n    percent_people_not_in_primary_school = mean(eduout_upsec_m, na.rm = TRUE),\n    mean_educ_years_20_24 = mean(eduyears_2024_m, na.rm = TRUE),\n    attend_higher_education = mean(attend_higher_1822_m, na.rm = TRUE),\n    number_complete_prim_1524 = mean(comp_prim_1524_no, na.rm = TRUE),\n    pisa_overall_mean = mean(OverallPisaScore2022),\n    pisa_math_mean = mean(PISAScoresScienceScore2022),\n    pisa_science_mean = mean(PISAScoresScienceScore2022),\n    pisa_reading_mean = mean(PISAScoresReadingScore2022)\n  )\n\npisa_summary\n\n# A tibble: 69 × 11\n   country  mean_primary_complet…¹ obs_primary_completi…² percent_people_not_i…³\n   &lt;chr&gt;                     &lt;dbl&gt;                  &lt;int&gt;                  &lt;dbl&gt;\n 1 Albania                   0.974                    230                 0.231 \n 2 Argenti…                  0.963                    453                 0.136 \n 3 Austral…                  0.993                     87                 0.0944\n 4 Austria                 NaN                          0               NaN     \n 5 Azerbai…                  0.975                    157                 0.151 \n 6 Belgium                 NaN                          0               NaN     \n 7 Brazil                    0.811                   4085                 0.164 \n 8 Bulgaria                NaN                          0               NaN     \n 9 Cambodia                  0.616                    851                 0.583 \n10 Canada                    0.997                     97                 0.0367\n# ℹ 59 more rows\n# ℹ abbreviated names: ¹​mean_primary_completion_rate,\n#   ²​obs_primary_completion_rate, ³​percent_people_not_in_primary_school\n# ℹ 7 more variables: mean_educ_years_20_24 &lt;dbl&gt;,\n#   attend_higher_education &lt;dbl&gt;, number_complete_prim_1524 &lt;dbl&gt;,\n#   pisa_overall_mean &lt;dbl&gt;, pisa_math_mean &lt;dbl&gt;, pisa_science_mean &lt;dbl&gt;,\n#   pisa_reading_mean &lt;dbl&gt;\n\n\nUsing this data, we have also made some relatively simple multivariate regression models. The linear regression model below examines the relationship betwee the PISA math score, and factors such as primary school completition rate, % of people not in primary school, mean education years for 20-24 yera olds, and % of people who attend higher education. From the coefficients it seems that all of these factors have a positive linear relationship with the PISA math score. However, the mean education years for 20-24 year olds has a negative relationship which is not what we would expect. This may be due to some sort of colinearity or homoscedacity, which we plan to examine in this coming week.\n\nlm_model &lt;- \n  linear_reg() |&gt; \n  set_engine(\"lm\")\n\nlm_form_fit2 &lt;- \n  lm_model |&gt; \n  fit(pisa_math_mean ~ mean_primary_completion_rate + percent_people_not_in_primary_school + mean_educ_years_20_24 + attend_higher_education, data = pisa_summary)\n\nlm_form_fit2\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = pisa_math_mean ~ mean_primary_completion_rate + \n    percent_people_not_in_primary_school + mean_educ_years_20_24 + \n    attend_higher_education, data = data)\n\nCoefficients:\n                         (Intercept)          mean_primary_completion_rate  \n                              231.47                                339.55  \npercent_people_not_in_primary_school                 mean_educ_years_20_24  \n                               22.55                                -17.28  \n             attend_higher_education  \n                              201.50  \n\n\nHere, we can see that the r^2 value is 0.353 which is not a super high r^2 value, so we will continue to refine our modeling in the coming week.\n\nbroom::glance(lm_form_fit2)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.353         0.201  40.2      2.32  0.0988     4  -110.  231.  238.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nbroom::augment(lm_form_fit2, new_data = pisa_summary)\n\n# A tibble: 69 × 13\n   .pred .resid country    mean_primary_completion_rate obs_primary_completion…¹\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                             &lt;dbl&gt;                    &lt;int&gt;\n 1  418.  -42.3 Albania                           0.974                      230\n 2  447.  -41.3 Argentina                         0.963                      453\n 3  NaN   NaN   Australia                         0.993                       87\n 4  NaN   NaN   Austria                         NaN                            0\n 5  406.  -26.1 Azerbaijan                        0.975                      157\n 6  NaN   NaN   Belgium                         NaN                            0\n 7  379.   24.2 Brazil                            0.811                     4085\n 8  NaN   NaN   Bulgaria                        NaN                            0\n 9  360.  -12.5 Cambodia                          0.616                      851\n10  NaN   NaN   Canada                            0.997                       97\n# ℹ 59 more rows\n# ℹ abbreviated name: ¹​obs_primary_completion_rate\n# ℹ 8 more variables: percent_people_not_in_primary_school &lt;dbl&gt;,\n#   mean_educ_years_20_24 &lt;dbl&gt;, attend_higher_education &lt;dbl&gt;,\n#   number_complete_prim_1524 &lt;dbl&gt;, pisa_overall_mean &lt;dbl&gt;,\n#   pisa_math_mean &lt;dbl&gt;, pisa_science_mean &lt;dbl&gt;, pisa_reading_mean &lt;dbl&gt;"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2024-03-04-post-1/post-1.html",
    "href": "posts/2024-03-04-post-1/post-1.html",
    "title": "Team 4 three datasets",
    "section": "",
    "text": "Dataset 1:Weekly United States COVID-19 Racial Data By State, April 12, 2020 to March 7, 2021\nURL: https://datadryad.org/stash/dataset/doi:10.7272/Q6TT4P68\nThe dataset contains 212,969 rows and 86 columns.The dataset in question originates from a joint effort by the COVID Tracking Project and Boston University’s Center for Antiracist Research. It has been actively compiled since April 12, 2020, with updates being made twice weekly. The data is sourced from the official public health websites of various states and territories, with the collection process being carried out by volunteers, whose names have been provided. The dataset comprises 54 columns and includes 5320 data points. One notable limitation of the dataset is the inconsistency in reporting the ethnicity data across different states, particularly regarding the categorization of Hispanic or Latino races—some states include this data while others do not. There are 13 columns dedicated to documenting COVID-19 cases across different ethnicities, but there are redundancies, such as the columns for Cases_Latinx and Cases_Ethnicity_Hispanic, which appear to contain similar, if not identical, data. Additionally, the dataset includes 13 columns each for deaths, hospitalizations, and total cases, all disaggregated by ethnicity. However, these sections have many missing entries, which could pose challenges for data cleaning and further analysis.\nQuestions want to answer based on the dataset: -Does the hospitalizations rate affect the deaths rate? -Which ethnicity or group of ethnicities has the highest deaths rate? - Is there a correlation between the hospitalization rate and the death rate due to COVID-19, and if so, how strong is this relationship? -Does the hospitalization rate for COVID-19 differ significantly among ethnic groups, and what might this reveal about access to healthcare or disease severity? - How have hospitalization and death rates evolved over time for each ethnicity, and are there noticeable trends or patterns? - Are there regional variations in the death and hospitalization rates among different ethnicities, and what might this indicate about local public health policies?\nDataset 2: Ethnicity disparities in school in United States URL: https://www.education-inequalities.org/countries/united-states The dataset provided by the World Inequality Database on Education (WIDE) tracks educational disparities across various countries, including the United States. From the 212,969 rows and 86 columns, it provides data on education outcomes differentiated by wealth, gender, ethnicity, and location, among other factors. This database can be significant for analyzing racial disparities in education. Meanwhile, the dataset provides numerous variables such as income, region, and completions of education which enable us to perform variable selection to find the best variable to show the correlation between racial disparities and education. We will likely face difficulties while cleaning the data since the dataset is relatively large with numerous outliers. Question want to answer based on the dataset: -How do educational outcomes vary by region and demographic groups in the USA?\n-How have educational outcomes been affected by race in the dataset?\nDataset 3: US Police Shootings URL: https://www.kaggle.com/datasets/ahsen1330/us-police-shootings?resource=download There are 4896 rows and 15 columns for this dataset. This data was collected from Kaggle amidst the covid 19 pandemic when many hate crimes directed towards specific races were happening. The dataset is consisted of 4896 rows and 15 columns.One challenge that we may face with this dataset is that it is on the smaller side. 5,000 rows is not necessarily small, but it is definitely not large either. If we want to conduct a very reliable study, it may be worth considering finding a dataset with more rows. Another problem that we may run into is that it will be difficult to assess whether a police killing was justified or not if we do not have more description on the crime. For example, if there was a column that described how long the altercation lasted, it may provide more insight into whether or not the crime was justified.\nQuestions want to answer based on the dataset: -Does race and age play a factor in who gets killed by the police? -How are the shooting crime related to the race and age group"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "MA415_team4",
    "section": "",
    "text": "This comes from the file about.qmd .\nThis is a website for the final project for MA[46]15 Data Science with R by Team TEAMNAME. The members of this team are below.\nJacob Park: Hi everyone, I’m Jacob and I am currently a junior stuyding applied mathematics with minors in economics and computer science.\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)"
  },
  {
    "objectID": "prelim_eda.html",
    "href": "prelim_eda.html",
    "title": "test",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tune         1.1.2\n✔ infer        1.0.5     ✔ workflows    1.1.3\n✔ modeldata    1.2.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.1     ✔ yardstick    1.2.0\n✔ recipes      1.0.9     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(broom)\nlibrary(scales) # for the label_comma() function\n\n\ndata &lt;- read_csv('dataset/educ.csv')\n\nRows: 212969 Columns: 86\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (14): iso_code, region_group, income_group, country, survey, level, cate...\ndbl (72): year, grade, comp_prim_v2_m, comp_lowsec_v2_m, comp_upsec_v2_m, co...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncontinent &lt;- read_csv('dataset/continents2.csv')\n\nRows: 249 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): name, alpha-2, alpha-3, iso_3166-2, region, sub-region, intermediat...\ndbl (4): country-code, region-code, sub-region-code, intermediate-region-code\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npisa &lt;- read_csv('dataset/pisa-scores-by-country-2024.csv')\n\nRows: 81 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): country\ndbl (5): OverallPisaScore2022, PISAScoresMathScore2022, PISAScoresScienceSco...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n#data\n#continent\n#pisa\n\n\ncontinent &lt;- continent |&gt;\n  rename(\n    country = name,\n    sub_region = `sub-region`\n  )\n\n#continent\nmerged_data &lt;- merge(data, continent, by = \"country\")\nmerged_data2 &lt;- merge(merged_data, pisa, by = \"country\")\n#merged_data\n\n\nafg &lt;- data |&gt;\n  filter(iso_code == 'AFG')\nafg\n\n# A tibble: 868 × 86\n   iso_code region_group  income_group country survey  year level grade category\n   &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;   \n 1 AFG      Central and … Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Ethnici…\n 2 AFG      Central and … Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Ethnici…\n 3 AFG      Central and … Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Ethnici…\n 4 AFG      Central and … Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Ethnici…\n 5 AFG      Central and … Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Ethnici…\n 6 AFG      Central and … Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Ethnici…\n 7 AFG      Central and … Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Ethnici…\n 8 AFG      Central and … Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Ethnici…\n 9 AFG      Central and … Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Location\n10 AFG      Central and … Low income … Afghan… DHS     2015 &lt;NA&gt;     NA Location\n# ℹ 858 more rows\n# ℹ 77 more variables: Sex &lt;chr&gt;, Location &lt;chr&gt;, Wealth &lt;chr&gt;, Region &lt;chr&gt;,\n#   Ethnicity &lt;chr&gt;, Religion &lt;chr&gt;, Language &lt;chr&gt;, comp_prim_v2_m &lt;dbl&gt;,\n#   comp_lowsec_v2_m &lt;dbl&gt;, comp_upsec_v2_m &lt;dbl&gt;, comp_prim_1524_m &lt;dbl&gt;,\n#   comp_lowsec_1524_m &lt;dbl&gt;, comp_upsec_2029_m &lt;dbl&gt;, eduyears_2024_m &lt;dbl&gt;,\n#   edu2_2024_m &lt;dbl&gt;, edu4_2024_m &lt;dbl&gt;, eduout_prim_m &lt;dbl&gt;,\n#   eduout_lowsec_m &lt;dbl&gt;, eduout_upsec_m &lt;dbl&gt;, comp_prim_v2_no &lt;dbl&gt;, …\n\n\n\ngrouped &lt;- data |&gt;\n  group_by(iso_code, Sex) |&gt;\n  summarise(mean = mean(comp_prim_v2_m, na.rm = TRUE), count = n())\n\n`summarise()` has grouped output by 'iso_code'. You can override using the\n`.groups` argument.\n\ngrouped\n\n# A tibble: 531 × 4\n# Groups:   iso_code [177]\n   iso_code Sex       mean count\n   &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt;\n 1 AFG      Female   0.348   278\n 2 AFG      Male     0.661   279\n 3 AFG      &lt;NA&gt;     0.520   311\n 4 AGO      Female   0.462   116\n 5 AGO      Male     0.560   114\n 6 AGO      &lt;NA&gt;     0.531   142\n 7 ALB      Female   0.976   291\n 8 ALB      Male     0.973   288\n 9 ALB      &lt;NA&gt;     0.974   398\n10 ARE      Female NaN       446\n# ℹ 521 more rows\n\n\n\ngrouped2 &lt;- data |&gt;\n  group_by(iso_code) |&gt;\n  summarise(mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n            mean_educ_years_20_24 = mean(eduyears_2024_m, na.rm = TRUE),\n            attend_higher_education = mean(attend_higher_1822_m, na.rm = TRUE),\n            count = n())\ngrouped2\n\n# A tibble: 177 × 5\n   iso_code mean_primary_completi…¹ mean_educ_years_20_24 attend_higher_educat…²\n   &lt;chr&gt;                      &lt;dbl&gt;                 &lt;dbl&gt;                  &lt;dbl&gt;\n 1 AFG                        0.510                  4.55                0.0784 \n 2 AGO                        0.519                  6.34              NaN      \n 3 ALB                        0.974                 10.4                 0.150  \n 4 ARE                      NaN                    NaN                 NaN      \n 5 ARG                        0.963                 11.4                 0.411  \n 6 ARM                        0.994                 10.8                 0.194  \n 7 AUS                        0.993                 12.4               NaN      \n 8 AUT                      NaN                    NaN                 NaN      \n 9 AZE                        0.975                 10.8                 0.132  \n10 BDI                        0.382                  4.26                0.00429\n# ℹ 167 more rows\n# ℹ abbreviated names: ¹​mean_primary_completion_rate, ²​attend_higher_education\n# ℹ 1 more variable: count &lt;int&gt;\n\n\n\ngrouped3 &lt;- merged_data |&gt;\n  #filter(survey == 'DHS') |&gt;\n  #filter(region_group %in% c('Central and Southern Asia', 'Europe and Northern America', 'Sub-Saharan Africa')) |&gt;\n  group_by(`sub_region`, year) |&gt;\n  summarise(mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n            percent_people_not_in_primary_school = mean(eduout_upsec_m, na.rm = TRUE),\n            mean_educ_years_20_24 = mean(eduyears_2024_m, na.rm = TRUE),\n            attend_higher_education = mean(attend_higher_1822_m, na.rm = TRUE),\n            count = n()\n            ) |&gt;\n  ggplot(aes(x = year, y = percent_people_not_in_primary_school, color = sub_region)) +\n    geom_line()\n\n`summarise()` has grouped output by 'sub_region'. You can override using the\n`.groups` argument.\n\ngrouped3\n\nWarning: Removed 80 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\ngrouped5 &lt;- merged_data |&gt;\n  #filter(survey == 'DHS') |&gt;\n  #filter(region_group %in% c('Central and Southern Asia', 'Europe and Northern America', 'Sub-Saharan Africa')) |&gt;\n  group_by(`sub_region`, year) |&gt;\n  summarise(mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n            percent_people_not_in_primary_school = mean(eduout_upsec_m, na.rm = TRUE),\n            mean_educ_years_20_24 = mean(eduyears_2024_m, na.rm = TRUE),\n            attend_higher_education = mean(attend_higher_1822_m, na.rm = TRUE),\n            number_complete_prim_1524 = mean(comp_prim_1524_no, na.rm = TRUE),\n            count = n()\n            ) |&gt;\n  ggplot(aes(x = year, y = mean_primary_completion_rate, color = sub_region)) +\n    geom_line()\n\n`summarise()` has grouped output by 'sub_region'. You can override using the\n`.groups` argument.\n\ngrouped5\n\nWarning: Removed 63 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\ngrouped6 &lt;- merged_data |&gt;\n  #filter(survey == 'DHS') |&gt;\n  #filter(region_group %in% c('Central and Southern Asia', 'Europe and Northern America', 'Sub-Saharan Africa')) |&gt;\n  group_by(region, year) |&gt;\n  summarise(mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n            percent_people_not_in_primary_school = mean(eduout_upsec_m, na.rm = TRUE),\n            mean_educ_years_20_24 = mean(eduyears_2024_m, na.rm = TRUE),\n            attend_higher_education = mean(attend_higher_1822_m, na.rm = TRUE),\n            number_complete_prim_1524 = mean(comp_prim_1524_no, na.rm = TRUE),\n            count = n()\n            ) |&gt;\n  ggplot(aes(x = year, y = mean_educ_years_20_24, color = region)) +\n    geom_line()\n\n`summarise()` has grouped output by 'region'. You can override using the\n`.groups` argument.\n\ngrouped6\n\nWarning: Removed 27 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\ngrouped7 &lt;- merged_data |&gt;\n  filter(sub_region %in% c('Northern Africa')) |&gt;\n  group_by(sub_region, Location) |&gt;\n  summarise(\n    mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n    count = n()\n  ) |&gt;\n  ggplot(\n    aes(x = Location, y = mean_primary_completion_rate, fill = Location) \n  )+geom_col() +ylim(c(0,1)) + labs(\n    title = 'Primary school completion rate of North Africans',\n    subtitle = 'This is data includes i) children and young people 3-5 years above primary school graduation age and ii) young people aged 15-24 years, who have completed primary school',\n    x = 'Location',\n    y = 'Primary school completion rate'\n  )\n\n`summarise()` has grouped output by 'sub_region'. You can override using the\n`.groups` argument.\n\ngrouped7\n\n\n\n\n\ngrouped8 &lt;- merged_data |&gt;\n  filter(sub_region %in% c('Sub-Saharan Africa')) |&gt;\n  group_by(sub_region, Location) |&gt;\n  summarise(\n    mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n    count = n()\n  ) |&gt;\n  ggplot(\n    aes(x = Location, y = mean_primary_completion_rate, fill = Location) \n  )+geom_col() +ylim(c(0,1)) + labs(\n    title = 'Primary school completion rate of Sub-Saharan Africans',\n    subtitle = 'This is data includes i) children and young people 3-5 years above primary school graduation age and ii) young people aged 15-24 years, who have completed primary school',\n    x = 'Location',\n    y = 'Primary school completion rate'\n  )\n\n`summarise()` has grouped output by 'sub_region'. You can override using the\n`.groups` argument.\n\ngrouped8\n\n\n\n\n\ngrouped9 &lt;- merged_data |&gt;\n  #filter(survey == 'DHS') |&gt;\n  filter(sub_region %in% c('Northern Africa')) |&gt;\n  group_by(iso_code) |&gt;\n  summarise(mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n            percent_people_not_in_primary_school = mean(eduout_upsec_m, na.rm = TRUE),\n            mean_educ_years_20_24 = mean(eduyears_2024_m, na.rm = TRUE),\n            attend_higher_education = mean(attend_higher_1822_m, na.rm = TRUE),\n            number_complete_prim_1524 = mean(comp_prim_1524_no, na.rm = TRUE),\n            count = n()\n            ) |&gt;\n  ggplot(aes(x = iso_code, y = mean_primary_completion_rate, fill = iso_code)) +\n    geom_col() +ylim(c(0,1))\ngrouped9\n\n\n\n\n\ngrouped10 &lt;- merged_data |&gt;\n  #filter(survey == 'DHS') |&gt;\n  filter(sub_region %in% c('Latin America and the Caribbean')) |&gt;\n  group_by(iso_code) |&gt;\n  summarise(mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n            percent_people_not_in_primary_school = mean(eduout_upsec_m, na.rm = TRUE),\n            mean_educ_years_20_24 = mean(eduyears_2024_m, na.rm = TRUE),\n            attend_higher_education = mean(attend_higher_1822_m, na.rm = TRUE),\n            number_complete_prim_1524 = mean(comp_prim_1524_no, na.rm = TRUE),\n            count = n()\n            ) |&gt;\n  ggplot(aes(x = iso_code, y = mean_primary_completion_rate, fill = iso_code)) +\n    geom_col() +ylim(c(0,1)) + theme(axis.text.x = element_text(angle = 45, hjust = 1))\ngrouped10\n\n\n\n\n\ngrouped11 &lt;- merged_data |&gt;\n  #filter(survey == 'DHS') |&gt;\n  filter(sub_region %in% c('Latin America and the Caribbean')) |&gt;\n  group_by(iso_code) |&gt;\n  summarise(mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n            obs_primary_completion_rate = sum(!is.na(comp_prim_v2_m)),\n            percent_people_not_in_primary_school = mean(eduout_upsec_m, na.rm = TRUE),\n            mean_educ_years_20_24 = mean(eduyears_2024_m, na.rm = TRUE),\n            attend_higher_education = mean(attend_higher_1822_m, na.rm = TRUE),\n            number_complete_prim_1524 = mean(comp_prim_1524_no, na.rm = TRUE),\n            count = n()\n            ) |&gt;\n  ggplot(aes(x = iso_code, y = obs_primary_completion_rate, fill = iso_code)) + geom_col() + theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\ngrouped11\n\n\n\n\n\nlm_model &lt;- \n  linear_reg() %&gt;% \n  set_engine(\"lm\")\n\ngrouped2 &lt;- data |&gt;\n  group_by(iso_code) |&gt;\n  summarise(mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n            mean_educ_years_20_24 = mean(eduyears_2024_m, na.rm = TRUE),\n            attend_higher_education = mean(attend_higher_1822_m, na.rm = TRUE),\n            count = n()) |&gt;\n  ungroup()\n\ngrouped2\n\n# A tibble: 177 × 5\n   iso_code mean_primary_completi…¹ mean_educ_years_20_24 attend_higher_educat…²\n   &lt;chr&gt;                      &lt;dbl&gt;                 &lt;dbl&gt;                  &lt;dbl&gt;\n 1 AFG                        0.510                  4.55                0.0784 \n 2 AGO                        0.519                  6.34              NaN      \n 3 ALB                        0.974                 10.4                 0.150  \n 4 ARE                      NaN                    NaN                 NaN      \n 5 ARG                        0.963                 11.4                 0.411  \n 6 ARM                        0.994                 10.8                 0.194  \n 7 AUS                        0.993                 12.4               NaN      \n 8 AUT                      NaN                    NaN                 NaN      \n 9 AZE                        0.975                 10.8                 0.132  \n10 BDI                        0.382                  4.26                0.00429\n# ℹ 167 more rows\n# ℹ abbreviated names: ¹​mean_primary_completion_rate, ²​attend_higher_education\n# ℹ 1 more variable: count &lt;int&gt;\n\n\n\nlm_model &lt;- \n  linear_reg() |&gt; \n  set_engine(\"lm\")\n\nlm_form_fit &lt;- \n  lm_model %&gt;% \n  fit(mean_primary_completion_rate ~ mean_educ_years_20_24, data = grouped2)\n\nlm_form_fit\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = mean_primary_completion_rate ~ mean_educ_years_20_24, \n    data = data)\n\nCoefficients:\n          (Intercept)  mean_educ_years_20_24  \n              0.12733                0.07119  \n\n\n\nsummary(lm_form_fit)\n\n             Length Class      Mode\nlvl           0     -none-     NULL\nspec          7     linear_reg list\nfit          13     lm         list\npreproc       1     -none-     list\nelapsed       1     -none-     list\ncensor_probs  0     -none-     list\n\n\n\nbroom::glance(lm_form_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.730         0.727 0.128      233. 3.54e-26     1   56.8 -108. -100.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nbroom::augment(lm_form_fit, new_data = grouped2)\n\n# A tibble: 177 × 7\n     .pred   .resid iso_code mean_primary_completion_rate mean_educ_years_20_24\n     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;                           &lt;dbl&gt;                 &lt;dbl&gt;\n 1   0.451   0.0594 AFG                             0.510                  4.55\n 2   0.579  -0.0591 AGO                             0.519                  6.34\n 3   0.867   0.107  ALB                             0.974                 10.4 \n 4 NaN     NaN      ARE                           NaN                    NaN   \n 5   0.939   0.0237 ARG                             0.963                 11.4 \n 6   0.895   0.0996 ARM                             0.994                 10.8 \n 7   1.01   -0.0179 AUS                             0.993                 12.4 \n 8 NaN     NaN      AUT                           NaN                    NaN   \n 9   0.897   0.0790 AZE                             0.975                 10.8 \n10   0.430  -0.0486 BDI                             0.382                  4.26\n# ℹ 167 more rows\n# ℹ 2 more variables: attend_higher_education &lt;dbl&gt;, count &lt;int&gt;\n\n\n\nggplot(grouped2, aes(x = mean_educ_years_20_24, y=mean_primary_completion_rate)) + geom_point() + geom_smooth() + geom_smooth(method = 'lm', color = 'red')\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 89 rows containing non-finite values (`stat_smooth()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 89 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 89 rows containing missing values (`geom_point()`).\n\n\n\n\n\n{r}lo ggplot(   broom::augment(lm_form_fit, new_data =grouped2), aes(x = .pred, y = .resid)   ) +    geom_point(alpha = 0.45, style = 'O', size = 2.5) +    ylim(c(-1,1)) +    geom_line(y =   0, color = 'red')\n\npisa_summary &lt;- merged_data2 |&gt;\n  group_by(country) |&gt;\n  summarise(\n    mean_primary_completion_rate = mean(comp_prim_v2_m, na.rm = TRUE),\n    obs_primary_completion_rate = sum(!is.na(comp_prim_v2_m)),\n    percent_people_not_in_primary_school = mean(eduout_upsec_m, na.rm = TRUE),\n    mean_educ_years_20_24 = mean(eduyears_2024_m, na.rm = TRUE),\n    attend_higher_education = mean(attend_higher_1822_m, na.rm = TRUE),\n    number_complete_prim_1524 = mean(comp_prim_1524_no, na.rm = TRUE),\n    pisa_overall_mean = mean(OverallPisaScore2022),\n    pisa_math_mean = mean(PISAScoresScienceScore2022),\n    pisa_science_mean = mean(PISAScoresScienceScore2022),\n    pisa_reading_mean = mean(PISAScoresReadingScore2022)\n  )\n\npisa_summary\n\n# A tibble: 69 × 11\n   country  mean_primary_complet…¹ obs_primary_completi…² percent_people_not_i…³\n   &lt;chr&gt;                     &lt;dbl&gt;                  &lt;int&gt;                  &lt;dbl&gt;\n 1 Albania                   0.974                    230                 0.231 \n 2 Argenti…                  0.963                    453                 0.136 \n 3 Austral…                  0.993                     87                 0.0944\n 4 Austria                 NaN                          0               NaN     \n 5 Azerbai…                  0.975                    157                 0.151 \n 6 Belgium                 NaN                          0               NaN     \n 7 Brazil                    0.811                   4085                 0.164 \n 8 Bulgaria                NaN                          0               NaN     \n 9 Cambodia                  0.616                    851                 0.583 \n10 Canada                    0.997                     97                 0.0367\n# ℹ 59 more rows\n# ℹ abbreviated names: ¹​mean_primary_completion_rate,\n#   ²​obs_primary_completion_rate, ³​percent_people_not_in_primary_school\n# ℹ 7 more variables: mean_educ_years_20_24 &lt;dbl&gt;,\n#   attend_higher_education &lt;dbl&gt;, number_complete_prim_1524 &lt;dbl&gt;,\n#   pisa_overall_mean &lt;dbl&gt;, pisa_math_mean &lt;dbl&gt;, pisa_science_mean &lt;dbl&gt;,\n#   pisa_reading_mean &lt;dbl&gt;\n\n\n\n# Assuming merged_data is your original data frame\namericas_pisa_long &lt;- merged_data2 %&gt;%\n  filter(region == 'Americas') %&gt;%\n  group_by(country) %&gt;%\n  summarise(\n    pisa_overall_mean = mean(OverallPisaScore2022, na.rm = TRUE),\n    pisa_math_mean = mean(PISAScoresMathScore2022, na.rm = TRUE), # Assuming you meant Math Score here\n    pisa_science_mean = mean(PISAScoresScienceScore2022, na.rm = TRUE),\n    pisa_reading_mean = mean(PISAScoresReadingScore2022, na.rm = TRUE)\n  ) %&gt;%\n  pivot_longer(\n    cols = starts_with(\"pisa_\"),\n    names_to = \"score_type\",\n    values_to = \"score\"\n  ) %&gt;%\n  mutate(score_type = factor(score_type, levels = c(\"pisa_overall_mean\", \"pisa_math_mean\", \"pisa_science_mean\", \"pisa_reading_mean\")))\n\n# Creating the plot\namericas_pisa_plot &lt;- americas_pisa_long %&gt;%\n  ggplot(aes(x = country, y = score, fill = score_type)) + \n  geom_col(position = \"dodge\") + \n  scale_y_continuous(labels = label_comma()) + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(y = \"PISA Score\", x = \"Country\", fill = \"Score Type\") +\n  scale_fill_brewer(palette = \"Pastel1\") # Using a color palette for better visual distinction\n\namericas_pisa_plot\n\n\n\n\n\nlm_form_fit2 &lt;- \n  lm_model |&gt; \n  fit(pisa_math_mean ~ mean_primary_completion_rate + percent_people_not_in_primary_school + mean_educ_years_20_24 + attend_higher_education + number_complete_prim_1524, data = pisa_summary)\n\nlm_form_fit2\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = pisa_math_mean ~ mean_primary_completion_rate + \n    percent_people_not_in_primary_school + mean_educ_years_20_24 + \n    attend_higher_education + number_complete_prim_1524, data = data)\n\nCoefficients:\n                         (Intercept)          mean_primary_completion_rate  \n                          240.097259                            333.303003  \npercent_people_not_in_primary_school                 mean_educ_years_20_24  \n                           19.638856                            -17.070005  \n             attend_higher_education             number_complete_prim_1524  \n                          200.908187                             -0.005233  \n\n\n\nbroom::glance(lm_form_fit2)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.358         0.158  41.3      1.79   0.173     5  -110.  233.  241.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nbroom::augment(lm_form_fit2, new_data = pisa_summary)\n\n# A tibble: 69 × 13\n   .pred .resid country    mean_primary_completion_rate obs_primary_completion…¹\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                             &lt;dbl&gt;                    &lt;int&gt;\n 1  420.  -43.6 Albania                           0.974                      230\n 2  448.  -42.2 Argentina                         0.963                      453\n 3  NaN   NaN   Australia                         0.993                       87\n 4  NaN   NaN   Austria                         NaN                            0\n 5  408.  -28.3 Azerbaijan                        0.975                      157\n 6  NaN   NaN   Belgium                         NaN                            0\n 7  375.   28.1 Brazil                            0.811                     4085\n 8  NaN   NaN   Bulgaria                        NaN                            0\n 9  361.  -14.2 Cambodia                          0.616                      851\n10  NaN   NaN   Canada                            0.997                       97\n# ℹ 59 more rows\n# ℹ abbreviated name: ¹​obs_primary_completion_rate\n# ℹ 8 more variables: percent_people_not_in_primary_school &lt;dbl&gt;,\n#   mean_educ_years_20_24 &lt;dbl&gt;, attend_higher_education &lt;dbl&gt;,\n#   number_complete_prim_1524 &lt;dbl&gt;, pisa_overall_mean &lt;dbl&gt;,\n#   pisa_math_mean &lt;dbl&gt;, pisa_science_mean &lt;dbl&gt;, pisa_reading_mean &lt;dbl&gt;\n\n\n\nlm_form_fit2 &lt;- \n  lm_model |&gt; \n  fit(pisa_overall_mean ~ mean_primary_completion_rate + percent_people_not_in_primary_school + mean_educ_years_20_24 + attend_higher_education + number_complete_prim_1524, data = pisa_summary)\n\nlm_form_fit2\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = pisa_overall_mean ~ mean_primary_completion_rate + \n    percent_people_not_in_primary_school + mean_educ_years_20_24 + \n    attend_higher_education + number_complete_prim_1524, data = data)\n\nCoefficients:\n                         (Intercept)          mean_primary_completion_rate  \n                           714.55301                             941.09518  \npercent_people_not_in_primary_school                 mean_educ_years_20_24  \n                            50.73041                             -46.17761  \n             attend_higher_education             number_complete_prim_1524  \n                           557.80429                              -0.02416  \n\n\n\nSection 1.3: Years of Edcuation\nAfter just two sections, it seems that there is a trend: Europe tends to have the “best education” while Africa seems to have “the worst education.” We will now explore college attendane as another measure of education.\n\n\n`summarise()` has grouped output by 'region'. You can override using the\n`.groups` argument.\n\n\nWarning: Removed 25 rows containing missing values (`geom_line()`).\n\n\n\n\n\nThis graph shows a similar result to the other graphs: Africa again ranks as the lowest.\n\n\nWarning: Removed 1 rows containing missing values (`position_stack()`).\n\n\n\n\n\n\n\nWarning: Removed 5 rows containing missing values (`position_stack()`)."
  },
  {
    "objectID": "dataExploration_yby.html",
    "href": "dataExploration_yby.html",
    "title": "Data Exploration",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5     ✔ rsample      1.2.0\n✔ dials        1.2.0     ✔ tune         1.1.2\n✔ infer        1.0.5     ✔ workflows    1.1.3\n✔ modeldata    1.2.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.1     ✔ yardstick    1.2.0\n✔ recipes      1.0.9     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(broom)\nEducation &lt;- read_csv('dataset/educ.csv')\n\nRows: 212969 Columns: 86\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (14): iso_code, region_group, income_group, country, survey, level, cate...\ndbl (72): year, grade, comp_prim_v2_m, comp_lowsec_v2_m, comp_upsec_v2_m, co...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nWe hope to focus on the category of Ethnicity\nDataEth &lt;- Education |&gt;\n  filter(category == 'Ethnicity')\nAs the Ethnicity is being divided too detailed, we hope to regather the ethnicity in simply a few groups, such as Asian, Hispanic, Black, White…We need to find another table in order to regroup."
  },
  {
    "objectID": "dataExploration_yby.html#by-location",
    "href": "dataExploration_yby.html#by-location",
    "title": "Data Exploration",
    "section": "By Location",
    "text": "By Location\n\nLocation_mean_edu_years &lt;- merged_data |&gt;\n  filter(category == 'Location') |&gt;   group_by(region, Location) %&gt;%\n  summarise(mean_educ_years = mean(eduyears_2024_m, na.rm = TRUE),count_non_missing = sum(!is.na(eduyears_2024_m)), .groups = 'drop')\n\nggplot(Location_mean_edu_years, aes(x = region, y = mean_educ_years, fill = Location)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +  scale_fill_manual(values = c(\"Rural\" = \"skyblue\", \"Urban\" = \"blue\")) + \n  geom_text(aes(label = sprintf(\"%.2f\", mean_educ_years)), position = position_dodge(width = 0.9), vjust = 5, size = 3.5, color = \"white\") + \n  labs(title = \"Average Education Years by Location and Region\",\n       x = \"Region\", y = \"Average Education Years\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nWarning: Removed 2 rows containing missing values (`geom_bar()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_text()`).\n\n\n\n\nLocation_mean_edu_years\n\n# A tibble: 12 × 4\n   region        Location mean_educ_years count_non_missing\n   &lt;chr&gt;         &lt;chr&gt;              &lt;dbl&gt;             &lt;int&gt;\n 1 Africa        Rural               4.88                82\n 2 Africa        Urban               8.31                82\n 3 Asia          Rural               8.42                51\n 4 Asia          Urban              10.2                 49\n 5 Europe        Rural              10.9                  2\n 6 Europe        Urban              13.5                  3\n 7 North America Rural               6.05                14\n 8 North America Urban               9.39                14\n 9 Oceania       Rural             NaN                    0\n10 Oceania       Urban             NaN                    0\n11 South America Rural               8.65                25\n12 South America Urban              11.0                 25\n\n\nAll the regions show that people in urban area has longer average education years for age group 20-24 years old. In general, the average education years is the longest in Europe while shortest in Africa."
  },
  {
    "objectID": "dataExploration_yby.html#by-sex",
    "href": "dataExploration_yby.html#by-sex",
    "title": "Data Exploration",
    "section": "By Sex",
    "text": "By Sex\n\nSex_mean_edu_years &lt;- merged_data |&gt;\n  filter(category == 'Sex') |&gt;   group_by(region, Sex) %&gt;%\n  summarise(mean_educ_years = mean(eduyears_2024_m, na.rm = TRUE), count_non_missing = sum(!is.na(eduyears_2024_m)), .groups = 'drop')\nggplot(Sex_mean_edu_years, aes(x = region, y = mean_educ_years, fill = Sex)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +  scale_fill_manual(values = c(\"Female\" = \"pink\", \"Male\" = \"black\")) + \n  geom_text(aes(label = sprintf(\"%.2f\", mean_educ_years)), position = position_dodge(width = 0.9), vjust = 5, size = 3.5, color = \"white\") + \n  labs(title = \"Average Education Years by Sex and Region\",\n       x = \"Region\", y = \"Average Education Years\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\nSex_mean_edu_years\n\n# A tibble: 12 × 4\n   region        Sex    mean_educ_years count_non_missing\n   &lt;chr&gt;         &lt;chr&gt;            &lt;dbl&gt;             &lt;int&gt;\n 1 Africa        Female            5.74                83\n 2 Africa        Male              6.94                83\n 3 Asia          Female            8.96                51\n 4 Asia          Male              9.40                51\n 5 Europe        Female           12.9                  3\n 6 Europe        Male             12.5                  3\n 7 North America Female            8.95                18\n 8 North America Male              8.92                18\n 9 Oceania       Female           13.0                  1\n10 Oceania       Male             12.3                  1\n11 South America Female           10.8                 27\n12 South America Male             10.4                 27"
  },
  {
    "objectID": "dataExploration_yby.html#by-ethnicitytoo-detailed",
    "href": "dataExploration_yby.html#by-ethnicitytoo-detailed",
    "title": "Data Exploration",
    "section": "by ethnicity[too detailed]",
    "text": "by ethnicity[too detailed]\n\n#count the number of distinct ethnicities\nnumber_of_distinct_ethnicities &lt;- DataEth %&gt;%\n  summarise(count_distinct_ethnicity = n_distinct(Ethnicity))\nnumber_of_distinct_ethnicities\n\n# A tibble: 1 × 1\n  count_distinct_ethnicity\n                     &lt;int&gt;\n1                      729\n\n#calculate the mean education years for age group 20-24 after grouping by region and ethnicity\nEthnicity_mean_edu_years &lt;- merged_data |&gt;\n  filter(category == 'Ethnicity') |&gt;   group_by(region, Ethnicity) %&gt;%\n  summarise(mean_educ_years = mean(eduyears_2024_m, na.rm = TRUE), count_non_missing = sum(!is.na(eduyears_2024_m)), .groups = 'drop')\n\n#plot the bar graph\nggplot(Ethnicity_mean_edu_years, aes(x = region, y = mean_educ_years, fill = Ethnicity)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) + \n  geom_text(aes(label = sprintf(\"%.2f\", mean_educ_years)), position = position_dodge(width = 0.9), vjust = 5, size = 3.5, color = \"white\") + \n  labs(title = \"Average Education Years by Ethnicity and Region\",\n       x = \"Region\", y = \"Average Education Years\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nWarning: Removed 268 rows containing missing values (`geom_bar()`).\n\n\nWarning: Removed 268 rows containing missing values (`geom_text()`).\n\n\n\n\nEthnicity_mean_edu_years\n\n# A tibble: 631 × 4\n   region Ethnicity                     mean_educ_years count_non_missing\n   &lt;chr&gt;  &lt;chr&gt;                                   &lt;dbl&gt;             &lt;int&gt;\n 1 Africa Acholi                                NaN                     0\n 2 Africa Adamaoua Oubangui                       5.40                  1\n 3 Africa Adja                                    3.87                  3\n 4 Africa Adja & Apparentes                     NaN                     0\n 5 Africa Adja Ewe                              NaN                     0\n 6 Africa Adja Ewe/Mina                           7.82                  1\n 7 Africa Affar                                   0.903                 2\n 8 Africa Affar / Adal, Danakil, Denkel           0.488                 1\n 9 Africa African                                 9.24                  1\n10 Africa Afrikaans                              10.8                   1\n# ℹ 621 more rows\n\n\nThere are 700+ distinct ethnicities which is over detailed that we are not able to apply this information to our analysis."
  },
  {
    "objectID": "dataExploration_yby.html#by-regiontoo-detailed",
    "href": "dataExploration_yby.html#by-regiontoo-detailed",
    "title": "Data Exploration",
    "section": "by Region[too detailed]",
    "text": "by Region[too detailed]\n\n#count the number of distinct regions\nnumber_of_distinct_regions &lt;- merged_data |&gt;\n  filter(category == 'Region') |&gt;\n  summarise(count_distinct_regions = n_distinct(Region))\nnumber_of_distinct_regions\n\n  count_distinct_regions\n1                   1308\n\n#calculate mean\nRegion_mean_edu_years &lt;- merged_data |&gt;\n  filter(category == 'Region') |&gt;   group_by(region, Region) %&gt;%\n  summarise(mean_educ_years = mean(eduyears_2024_m, na.rm = TRUE),count_non_missing = sum(!is.na(eduyears_2024_m)), .groups = 'drop')\n#plot bar graph\nggplot(Region_mean_edu_years, aes(x = region, y = mean_educ_years, fill = Region)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) + \n  geom_text(aes(label = sprintf(\"%.2f\", mean_educ_years)), position = position_dodge(width = 0.9), vjust = 5, size = 3.5, color = \"white\") + \n  labs(title = \"Average Education Years by Region and region\",\n       x = \"Region\", y = \"Average Education Years\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nWarning: Removed 485 rows containing missing values (`geom_bar()`).\n\n\nWarning: Removed 485 rows containing missing values (`geom_text()`).\n\n\n\n\nRegion_mean_edu_years\n\n# A tibble: 1,344 × 4\n   region Region      mean_educ_years count_non_missing\n   &lt;chr&gt;  &lt;chr&gt;                 &lt;dbl&gt;             &lt;int&gt;\n 1 Africa Abia                 NaN                    0\n 2 Africa Adamaoua               5.12                 2\n 3 Africa Adamawa              NaN                    0\n 4 Africa Addis Ababa            8.59                 3\n 5 Africa Adrar                NaN                    0\n 6 Africa Afar                   2.34                 3\n 7 Africa Agadez                 3.06                 2\n 8 Africa Akwa Ibom            NaN                    0\n 9 Africa Al Gadarif           NaN                    0\n10 Africa Al Gazira            NaN                    0\n# ℹ 1,334 more rows"
  },
  {
    "objectID": "dataExploration_yby.html#by-wealth",
    "href": "dataExploration_yby.html#by-wealth",
    "title": "Data Exploration",
    "section": "by wealth",
    "text": "by wealth\n\nWealth_mean_edu_years &lt;- merged_data |&gt;\n  filter(category == 'Wealth') |&gt;   group_by(region, Wealth) %&gt;%\n  summarise(mean_educ_years = mean(eduyears_2024_m, na.rm = TRUE), count_non_missing = sum(!is.na(eduyears_2024_m)), .groups = 'drop')\n\nggplot(Wealth_mean_edu_years, aes(x = region, y = mean_educ_years, fill = Wealth)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  geom_text(aes(label = sprintf(\"%.2f\", mean_educ_years)), position = position_dodge(width = 0.9), vjust = 5, size = 3.5, color = \"black\") + \n  labs(title = \"Average Education Years by Wealth and Region\",\n       x = \"Region\", y = \"Average Education Years\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\nWealth_mean_edu_years\n\n# A tibble: 30 × 4\n   region Wealth     mean_educ_years count_non_missing\n   &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;             &lt;int&gt;\n 1 Africa Quintile 1            3.51                72\n 2 Africa Quintile 2            4.56                72\n 3 Africa Quintile 3            5.55                72\n 4 Africa Quintile 4            6.88                72\n 5 Africa Quintile 5            9.32                72\n 6 Asia   Quintile 1            7.11                46\n 7 Asia   Quintile 2            8.21                46\n 8 Asia   Quintile 3            9.00                46\n 9 Asia   Quintile 4           10.0                 46\n10 Asia   Quintile 5           11.6                 46\n# ℹ 20 more rows\n\n\nFor all regions, the higher the wealth level, the longer the average education years. However, we should be careful that some regions only have a few data. For example, Oceania only has 1 data for each quintile and Europe only has 3 data points for each quintile, which may cause data collection bias."
  },
  {
    "objectID": "dataExploration_yby.html#by-religiontoo-detailed-but-can-do-some-data-cleaning",
    "href": "dataExploration_yby.html#by-religiontoo-detailed-but-can-do-some-data-cleaning",
    "title": "Data Exploration",
    "section": "by religion[too detailed but can do some data cleaning]",
    "text": "by religion[too detailed but can do some data cleaning]\n\nReligion_mean_edu_years &lt;- merged_data |&gt;\n  filter(category == 'Religion') |&gt;   group_by(region, Religion) %&gt;%\n  summarise(mean_educ_years = mean(eduyears_2024_m, na.rm = TRUE), count_non_missing = sum(!is.na(eduyears_2024_m)), .groups = 'drop')\n\nggplot(Religion_mean_edu_years, aes(x = region, y = mean_educ_years, fill = Religion)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  geom_text(aes(label = sprintf(\"%.2f\", mean_educ_years)), position = position_dodge(width = 0.9), vjust = 5, size = 3.5, color = \"black\") + \n  labs(title = \"Average Education Years by Religion and Region\",\n       x = \"Region\", y = \"Average Education Years\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nWarning: Removed 52 rows containing missing values (`geom_bar()`).\n\n\nWarning: Removed 52 rows containing missing values (`geom_text()`).\n\n\n\n\nReligion_mean_edu_years\n\n# A tibble: 120 × 4\n   region Religion                 mean_educ_years count_non_missing\n   &lt;chr&gt;  &lt;chr&gt;                              &lt;dbl&gt;             &lt;int&gt;\n 1 Africa .                                   6.95                 4\n 2 Africa Adventist                           5.58                 2\n 3 Africa Adventist/Jehova                    7.50                 1\n 4 Africa Anglican                            7.12                 5\n 5 Africa Animist                             3.76                 3\n 6 Africa Animiste/Pas De Religion          NaN                    0\n 7 Africa Apostolic Sect                      8.71                 4\n 8 Africa Armee De Salut                    NaN                    0\n 9 Africa Assemblee De Dieu                 NaN                    0\n10 Africa Assembly Of God                     7.53                 2\n# ℹ 110 more rows"
  },
  {
    "objectID": "dataExploration_yby.html#anova-for-sex-wealth-and-location-vs.-mean-education-years-20_24",
    "href": "dataExploration_yby.html#anova-for-sex-wealth-and-location-vs.-mean-education-years-20_24",
    "title": "Data Exploration",
    "section": "ANOVA for Sex, Wealth, and Location vs. Mean Education Years 20_24",
    "text": "ANOVA for Sex, Wealth, and Location vs. Mean Education Years 20_24\n\nlibrary(dplyr)\n\n# Assuming your data is in a dataframe called data\nSexdata &lt;- merged_data |&gt;\n  filter(category == 'Sex')\nLocationdata &lt;- merged_data |&gt;\n  filter(category == 'Location')\nWealthdata &lt;- merged_data |&gt;\n  filter(category == 'Wealth')\n\n# Perform ANOVA to check if mean of y differs by categories of each categorical variable\nanova_cat1 &lt;- aov(eduyears_2024_m ~ Sex, data = Sexdata)\nanova_cat2 &lt;- aov(eduyears_2024_m ~ Location, data = Locationdata)\nanova_cat3 &lt;- aov(eduyears_2024_m ~ Wealth, data = Wealthdata)\n\n# Get the summaries of the ANOVA tests\nsummary(anova_cat1)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)  \nSex           1   32.3   32.28   3.761 0.0532 .\nResiduals   364 3124.1    8.58                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n4006 observations deleted due to missingness\n\nsummary(anova_cat2)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nLocation      1  676.7   676.7   100.5 &lt;2e-16 ***\nResiduals   345 2322.1     6.7                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n3879 observations deleted due to missingness\n\nsummary(anova_cat3)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nWealth        4   2463   615.8   64.31 &lt;2e-16 ***\nResiduals   810   7757     9.6                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n9307 observations deleted due to missingness\n\n\nAs p value is smaller than alpha = 0.05 for Location and Wealth, the two categorical values are statistically significant to the average education years."
  },
  {
    "objectID": "dataExploration_yby.html#by-location-1",
    "href": "dataExploration_yby.html#by-location-1",
    "title": "Data Exploration",
    "section": "By Location",
    "text": "By Location\n\nlibrary(tidyverse)\n\n#Boxplots for Urban Only\nUrban &lt;- merged_data %&gt;%\n  filter(category == 'Location') |&gt; filter(Location == \"Urban\")\n# Reshaping the data from wide to long format\nlong_data &lt;- Urban %&gt;%\n  pivot_longer(\n    cols = c(comp_prim_v2_m, comp_prim_1524_m, comp_lowsec_v2_m, comp_lowsec_1524_m, comp_upsec_v2_m, comp_upsec_2029_m), \n    names_to = \"variable\", \n    values_to = \"value\"\n  )\n\n# Creating the box plot with all variables\nggplot(long_data, aes(x = variable, y = value)) +\n  geom_boxplot() +\n  labs(title = \"Box plot of Variables in Location of Urban\", \n       x = \"\", \n       y = \"Completion Rate\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x labels if needed\n\nWarning: Removed 10571 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n#Boxplots for Rural Only {may mainly focus on this location where needs more education resources}\nRural &lt;- merged_data %&gt;%\n  filter(category == 'Location') |&gt; filter(Location == \"Rural\")\n# Reshaping the data from wide to long format\nlong_data &lt;- Rural %&gt;%\n  pivot_longer(\n    cols = c(comp_prim_v2_m, comp_prim_1524_m, comp_lowsec_v2_m, comp_lowsec_1524_m, comp_upsec_v2_m, comp_upsec_2029_m), \n    names_to = \"variable\", \n    values_to = \"value\"\n  )\n\n# Creating the box plot with all variables\nggplot(long_data, aes(x = variable, y = value)) +\n  geom_boxplot() +\n  labs(title = \"Box plot of Variables in Location of Rural\", \n       x = \"\", \n       y = \"Completion Rate\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x labels if needed\n\nWarning: Removed 10309 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nAs we expected, the primary completion rate &gt; the lower secondary completion rate &gt; the higher secondary completion rate, indicated by the box (Q1, median, Q3) that the median primary completion rates approaches or greater than 0.75. Also, we found that the general completion rate at rural is lower than that in urban area."
  },
  {
    "objectID": "dataExploration_yby.html#try-simple-linear-regression",
    "href": "dataExploration_yby.html#try-simple-linear-regression",
    "title": "Data Exploration",
    "section": "Try Simple Linear Regression",
    "text": "Try Simple Linear Regression\n\nlibrary(ggplot2)\nlibrary(gridExtra)  # For arranging the plots\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n# Assume your dependent variable is named 'y' and your data is in a dataframe named 'data'\nLocation &lt;- merged_data %&gt;%\n  filter(category == 'Location') \n# Create a list of plots\nplots &lt;- list()\nvariables &lt;- c(\"comp_prim_v2_m\", \"comp_prim_1524_m\", \"comp_lowsec_v2_m\", \n               \"comp_lowsec_1524_m\", \"comp_upsec_v2_m\", \"comp_upsec_2029_m\")\n\nfor (var in variables) {\n  p &lt;- ggplot(Location, aes_string(x = var, y = \"eduyears_2024_m\")) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = TRUE) +\n    labs(title = paste(\"Regression of y on\", var),\n         x = var, \n         y = \"y\")\n  plots[[var]] &lt;- p\n}\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n# Arrange the plots in a grid\ndo.call(gridExtra::grid.arrange, plots)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 3879 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 3879 rows containing missing values (`geom_point()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 3899 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 3899 rows containing missing values (`geom_point()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 3881 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 3881 rows containing missing values (`geom_point()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 3901 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 3901 rows containing missing values (`geom_point()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 3883 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 3883 rows containing missing values (`geom_point()`).\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 3907 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 3907 rows containing missing values (`geom_point()`).\n\n\n\n\n\nMulticolinearity: because the secondary completion rates highly depends on the primary completion rate, so we will not use all of them [just pick one of them]. Remove the ones for upper secondary because the ages(either 3-5 above 18, which will be 21-23, or 20-29) is already over 20-24 age groups."
  }
]